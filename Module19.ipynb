{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Basic Neural Network"
      ],
      "metadata": {
        "id": "rgfYuXPGnyEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import out dependencies\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "import sklearn as skl\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qgDG1rc8n8jm"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### scikit-learn's make_blobs creates sample values and contains many parameters that cgange the shape and values of the sample dataset. For our purposes, we use it to create 1000 samples with two features (x-axis and y-axis) that are linearly separable into two groups\n"
      ],
      "metadata": {
        "id": "i5iHDJe5osO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dummy dataset\n",
        "X,y = make_blobs(n_samples = 1000, centers = 2, n_features = 2, random_state = 78)\n",
        "\n",
        "# creating a DataFrame with the dummy data\n",
        "df = pd.DataFrame(X, columns = ['Feature 1', 'Feature 2'])\n",
        "df['Target'] = y\n",
        "\n",
        "# plotting the dummy data\n",
        "df.plot.scatter(x='Feature 1', y='Feature 2', c='Target', colormap = 'winter')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "6VkE5PgWpJ_i",
        "outputId": "a8c6b7c8-b40c-4902-d6c2-459de2f4d498"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb508a26890>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### once we have our dummy data generated, we split data into training and testing dataset using scikit-learn's train_test_split"
      ],
      "metadata": {
        "id": "C8zhiLSUp4_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use sklearn to split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 78)"
      ],
      "metadata": {
        "id": "5tNxHpSHqCcm"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now we have training data, we need to prepare the dataset for our neural network model. like other machine learning algorithm, it is crucial to normalize or standardize our numerical variables to ensure that our neural network does not focus on outliers and can apply proper weights to each output. \n",
        "\n",
        "### In most cases, the more that input variables are normalized to the same scale, the more stable the neural network model is and the better neural network model will generalize"
      ],
      "metadata": {
        "id": "oeZEaz50qQqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create scaler instance\n",
        "X_scaler = skl.preprocessing.StandardScaler()\n",
        "\n",
        "# fit the scaler\n",
        "X_scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Jifmj4y8q94r"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## we have our data ready for our first neural network model. first we must create our sequential model"
      ],
      "metadata": {
        "id": "j6RUSW8RrW7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the Keras Sequential model\n",
        "nn_model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "I9HcQ7-yrezv"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### the nn_model object will store the entire architecture of our neural network model. Next, we add our first layer which will contain our inputs and hidden layer of neurons"
      ],
      "metadata": {
        "id": "4JGwf6dirn5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we add layers to our sequential model using Keras' Dense class\n",
        "\n",
        "### input_dim parameter indicates how many inputs will be in the model\n",
        "### units parameter indicates how many neurons we want in the hidden layer\n",
        "### activation parameter indicates which activation function to use"
      ],
      "metadata": {
        "id": "Zffo5BZBsDY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add our first dense layer, including the input layer\n",
        "nn_model.add(tf.keras.layers.Dense(units = 1, activation='relu', input_dim= 2))"
      ],
      "metadata": {
        "id": "7ZyOFjItsb7r"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now we need to supply the number of output neurons. for classification model, we only want yes or no binary decision therefore we only need one output neuron.\n",
        "\n",
        "### we used ReLU function to enable nonlinear relationships, however for our classification output we want to use a sigmoid activation function to produce a probability output"
      ],
      "metadata": {
        "id": "yN5tbPDes-te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the output layer that uses probability activation function\n",
        "nn_model.add(tf.keras.layers.Dense(units = 1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "mEr7_Ftktdgh"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now we have added our layers to the Sequential model, we can double check our model structure using the summary method"
      ],
      "metadata": {
        "id": "N4KLvd1Dtr8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the structure of the sequential model\n",
        "nn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7bV0U16t0Ie",
        "outputId": "1e089167-ddd2-42b3-b689-1c41635f7e11"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 1)                 3         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 5\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Compiling** : the process of informing the model how it should learn and train \n",
        "\n",
        "### **Optimization Function** : shapes and molds a nrural network model while it is being trained and ensure that it performs to the best of its ability\n",
        "\n",
        "### **Loss Metric** : is used by machine learning algorithms to score the performance of the model through each iteration and epoch by evaluating the inaccuracy of a single input\n",
        "\n",
        "### **Evaluation Metric** : measures the quality of the machine learning model. 2types: model predictive accuracy and model mean squared error"
      ],
      "metadata": {
        "id": "Mvdxnx6QuQRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the sequential model together and customize metrics\n",
        "nn_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "# we use the adam optimizer which uses a graient descent approach to ensur ethat the algorithm will not get stuck on weaker classifying variables and features\n",
        "# for the loss function, we will use binary_crossentropy which specifically designed to evaluate a binary classification model"
      ],
      "metadata": {
        "id": "shUW7eKt0RAK"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and Test a Basic Neural Network**"
      ],
      "metadata": {
        "id": "mLHMFybN06W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the training data\n",
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs = 100)\n",
        "# each epoch is a complete pass through the training data. like tensorflow playground"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ia15VG1FyQ",
        "outputId": "0813497f-4509-43d9-c229-c401932b8768"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 1s 2ms/step - loss: 0.7789 - accuracy: 0.0533\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7667 - accuracy: 0.0440\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 0.0480\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7469 - accuracy: 0.0600\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.7391 - accuracy: 0.0653\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7324 - accuracy: 0.0760\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7264 - accuracy: 0.0880\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7212 - accuracy: 0.0960\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7168 - accuracy: 0.1120\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7129 - accuracy: 0.1253\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.1400\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7065 - accuracy: 0.1680\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.1880\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.1987\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.2227\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.2867\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.3840\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4840\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.4933\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.4933\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.4933\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.4933\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5627\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.9053\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.9013\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6761 - accuracy: 0.9053\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.9133\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.9160\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.9293\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.9373\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.9413\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.9533\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.9573\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6079 - accuracy: 0.9613\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.9640\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.9680\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.9707\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.9747\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.9773\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.9827\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.9840\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.9853\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.9853\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.9853\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.9867\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.9880\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.9880\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.9880\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.9880\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.9880\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.9880\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.9880\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.9893\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.9907\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.9920\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.9920\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.9920\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2877 - accuracy: 0.9920\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9920\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9920\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.9920\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9920\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.9920\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9920\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9920\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9920\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9920\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2214 - accuracy: 0.9933\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9947\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9947\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.9960\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9960\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.9973\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9973\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9973\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9973\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9987\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9987\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1613 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### looking above the model training output. we know the loss metric was 0.0712 and the predictive accuracy is 1.0. this means that although our model performance had more loss than the simulation data, the model correctly classifies all of our training data which is sufficient for our need. "
      ],
      "metadata": {
        "id": "W242x3Wg1nai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### when training completes, the model object stores the loss and accuracy metrics across all epochs which we can use to visualize the traing progress\n"
      ],
      "metadata": {
        "id": "oJsQGMnm2KHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crate a dataframe containing training history\n",
        "history_df = pd.DataFrame(fit_model.history, index = range(1, len(fit_model.history['loss'])+1))\n",
        "\n",
        "# plot the loss\n",
        "history_df.plot(y='loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "wwi6m4ve2XNL",
        "outputId": "d293ba63-6031-4d0a-fae4-70f22328a86d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb5088673d0>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### similarly we can plot the accuracy over time using the same DataFrame"
      ],
      "metadata": {
        "id": "vrjw73Cz20cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the accuracy\n",
        "history_df.plot(y='accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "C_pKalA126GA",
        "outputId": "68abf4c0-0299-4700-c10d-b11d210a37a4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb50801e650>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f'Loss: {model_loss}, Accuracy: {model_accuracy}')\n",
        "\n",
        "# from the output, the model is correctly classify data it was not trained on 100% of the time\n",
        "# it is important to establish model performance thresholds before designing any machin learning model\n",
        "# depending on the type of data and the use case, we may have to recreate and retrain a model using different parameters, different training/testing data or even look to use a different model entirely"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfALNYAg5EaS",
        "outputId": "96e04357-0a4f-41ba-c963-169cf08206e4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 - 0s - loss: 0.1055 - accuracy: 1.0000 - 135ms/epoch - 17ms/step\n",
            "Loss: 0.10550287365913391, Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we have a trained neural network model and we have verified its performance using a test dataset, we cn apply this model to novel datasets and predict the classification of a data point\n",
        "### we can use the predict method to generate predictions on new data"
      ],
      "metadata": {
        "id": "FyLD0pi67E0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the classification of a new set of blob data\n",
        "new_X, new_y = make_blobs(n_samples = 10, centers = 2, n_features=2, random_state = 78)\n",
        "new_X_scaled = X_scaler.transform(new_X)\n",
        "(nn_model.predict(new_X_scaled) > 0.5).astype('int32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dYEERO87YEc",
        "outputId": "c098ddd1-dcb4-4ff8-a599-7294b9adc9ad"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Nuances of Neural Networks on Nonlinear Numbers**"
      ],
      "metadata": {
        "id": "ponZgRho8G9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a simple linear regression and singular perceptron models wotk really well as a binary classifier when the data is linearly separable.\n",
        "\n",
        "## but what about nonlinear data? \n",
        "### to test this bahavior, lets generate some new dummy data. this time we will generate some nonlinear moon-shaped data using scikit-learn's make_moons method and visualize it using pd and matplotlib"
      ],
      "metadata": {
        "id": "Uw02l4hD9qNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "# Creating dummy nonlinear data\n",
        "X_moons, y_moons = make_moons(n_samples=1000, noise=0.08, random_state=78)\n",
        "\n",
        "# Transforming y_moons to a vertical vector\n",
        "y_moons = y_moons.reshape(-1, 1)\n",
        "\n",
        "# Creating a DataFrame to plot the nonlinear dummy data\n",
        "df_moons = pd.DataFrame(X_moons, columns=[\"Feature 1\", \"Feature 2\"])\n",
        "df_moons[\"Target\"] = y_moons\n",
        "\n",
        "# Plot the nonlinear dummy data\n",
        "df_moons.plot.scatter(x=\"Feature 1\",y=\"Feature 2\", c=\"Target\",colormap=\"winter\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "J4HGTi6Y-PFh",
        "outputId": "98766b3d-4d22-4f0a-de29-b0ca94f66ee5"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb507f3ad50>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing sets\n",
        "X_moon_train, X_moon_test, y_moon_train, y_moon_test = train_test_split(\n",
        "    X_moons, y_moons, random_state=78\n",
        ")\n",
        "\n",
        "# Create the scaler instance\n",
        "X_moon_scaler = skl.preprocessing.StandardScaler()\n",
        "\n",
        "# Fit the scaler\n",
        "X_moon_scaler.fit(X_moon_train)\n",
        "\n",
        "# Scale the data\n",
        "X_moon_train_scaled = X_moon_scaler.transform(X_moon_train)\n",
        "X_moon_test_scaled = X_moon_scaler.transform(X_moon_test)"
      ],
      "metadata": {
        "id": "_Yz2oD_t-oin"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model with the nonlinear data\n",
        "model_moon = nn_model.fit(X_moon_train_scaled, y_moon_train, epochs=100, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45bWJbDI-uX0",
        "outputId": "4a87d2c1-7ebc-430b-ed07-1d99dc87c78c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.1546 - accuracy: 0.3933\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.4160\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.4320\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8866 - accuracy: 0.4560\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8449 - accuracy: 0.4720\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8135 - accuracy: 0.4880\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7881 - accuracy: 0.5027\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7670 - accuracy: 0.5213\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7487 - accuracy: 0.5333\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.5413\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.5560\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.5667\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.5733\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.5840\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6726 - accuracy: 0.5880\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.5947\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6027\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6107\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6389 - accuracy: 0.6160\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6227\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6333\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6347\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6373\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6387\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6427\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.6440\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.6467\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6520\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.6547\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.6547\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.6600\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6613\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.6667\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.6680\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5545 - accuracy: 0.6693\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.6760\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.6787\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.6813\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.6827\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.6880\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.6973\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7000\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7053\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7080\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7120\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7160\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7187\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.7187\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.7213\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7253\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7253\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7267\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7280\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7280\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7347\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7360\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7387\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7400\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7427\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7480\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7480\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7480\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7520\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7547\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7560\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7587\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7600\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7627\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7627\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7707\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7747\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7813\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7853\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.7867\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.7880\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7893\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7907\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.7907\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.7947\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.7973\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8013\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8040\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8067\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8067\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8093\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8120\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8147\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8173\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8200\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8240\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8280\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8307\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8320\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8373\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8400\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8427\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8427\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8453\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8453\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### this time our single-neuron, single-layer neural network was unable to accurately classify all of our training data"
      ],
      "metadata": {
        "id": "f_1H442--2xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame containing training history\n",
        "history_df = pd.DataFrame(model_moon.history, index=range(1,len(model_moon.history[\"loss\"])+1))\n",
        "\n",
        "# Plot the loss\n",
        "history_df.plot(y=\"loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "muHKN2nc_u39",
        "outputId": "7b84aec2-0f15-41af-ff8d-405e336c53f6"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb507dd8f90>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhcd33v8fdXu7UvM5IXyYsseYvtOLbsxHsak8YJS4DQ3IQCcUqS25YAvbS5paW9pTy0odASSG9LCNQQlkACzQWTBEI2W17jRbEdr7Ikb/KmGdmSV1nS6Hf/mLEfESxbtiQfzZnP63n0RDNzrPM9z3E+/ul7fud3zDmHiIjEvySvCxARkf6hQBcR8QkFuoiITyjQRUR8QoEuIuITKV7tOBAIuNGjR3u1exGRuLRp06awcy54qc88C/TRo0ezceNGr3YvIhKXzGx/T5+p5SIi4hMKdBERn1Cgi4j4hGc9dBGR/tDR0UFjYyNtbW1el9KvMjIyKC0tJTU1tdd/RoEuInGtsbGRnJwcRo8ejZl5XU6/cM7R3NxMY2MjY8aM6fWfU8tFROJaW1sbRUVFvglzADOjqKjoqn/rUKCLSNzzU5hfcC3HFHeBvnHfcf7lN7vQsr8iIr8r7gJ9a2Mr31peT8vZDq9LEREBIDs72+sSgDgM9JLcDACOnfLXFW0Rkb6Kw0BPB+DYyfMeVyIi8rucczz22GNMnjyZKVOm8NxzzwFw5MgRFixYwLRp05g8eTIrV64kEomwZMmSi9s+8cQTfd5/3E1bvDhCP6kRuoj8rn/81XZ2HD7Zrz9z0vBc/uH9N/Rq2xdeeIHNmzezZcsWwuEwM2fOZMGCBTz77LPccccdfOELXyASiXD27Fk2b97MoUOH2LZtGwAtLS19rjXuRujBnOgIvUmBLiKDzKpVq7j//vtJTk6mpKSEhQsXsmHDBmbOnMn3vvc9vvjFL/LOO++Qk5NDeXk5DQ0NfPrTn+Y3v/kNubm5fd5/3I3QM1KTyc9MVctFRH5Pb0fS19uCBQuorq7mpZdeYsmSJXzuc5/jE5/4BFu2bOGVV17hqaee4vnnn2fp0qV92k/cjdABSnIy1HIRkUFn/vz5PPfcc0QiEUKhENXV1cyaNYv9+/dTUlLCww8/zEMPPURNTQ3hcJiuri7uuecevvzlL1NTU9Pn/cfdCB2gODddgS4ig86HPvQh1q5dy4033oiZ8dWvfpWhQ4fyzDPP8LWvfY3U1FSys7P5wQ9+wKFDh3jwwQfp6uoC4PHHH+/z/s2rG3SqqqrctT7g4rGfbWHlnjDr/nZRP1clIvFm586dTJw40esyBsSljs3MNjnnqi61fXy2XHIzCJ0+T6RLd4uKiFwQp4GeTqTL0XxGF0ZFRC6Iy0Avjs1Fb9JMFxEBX67tdC3HFJeBrpuLROSCjIwMmpubfRXqF9ZDz8jIuKo/F5ezXHT7v4hcUFpaSmNjI6FQyOtS+tWFJxZdjbgM9EB2OmYaoYsIpKamXtVTffwsLlsuqclJFGWl06QVF0VELorLQAcYmpfO0VYFuojIBXEb6NHb/9VDFxG5IG4DvTg3Qy0XEZFu4jbQS3LTCZ9upyPS5XUpIiKDQhwHenR+ZuiU2i4iIhDXgX5hLrraLiIiEMeBXpxz4W5RjdBFRCCOA/1Cy0UXRkVEouI20Iuy0khJMs1FFxGJidtAT0oyinPS1XIREYmJ20AHzUUXEekurgO9RM8WFRG5KM4DXbf/i4hcEPeB3nqug7aOiNeliIh4Lq4DfWhs6uLhlnMeVyIi4r24DvTRgSwA9obPeFyJiIj34jrQxwajgd4QUqCLiMR1oOdnplGYlUZD+LTXpYiIeO6KgW5mS82sycy29fC5mdmTZlZnZlvNbHr/l9mzMYEs6jVCFxHp1Qj9+8Diy3x+J1AZ+3oE+Fbfy+q98kCWWi4iIvQi0J1z1cDxy2xyN/ADF7UOyDezYf1V4JWUB7MJnz7PybaO67VLEZFBqT966COAg91eN8be+z1m9oiZbTSzjaFQqB92DeWxC6N7NUoXkQR3XS+KOueeds5VOeeqgsFgv/zMizNddGFURBJcfwT6IaCs2+vS2HvXRVlhJkmmqYsiIv0R6MuAT8Rmu9wCtDrnjvTDz+2V9JRkygozFegikvBSrrSBmf0EuBUImFkj8A9AKoBz7ingZeAuoA44Czw4UMX2pDyQRYPuFhWRBHfFQHfO3X+Fzx3wqX6r6BqUB7NZ29BMV5cjKcm8LEVExDNxfafoBeXBLNo6ujiitdFFJIH5ItDHBC6s6aKZLiKSuHwR6GOD2YBmuohIYvNFoBfnpJOVlqwRuogkNF8EuplRHszWTBcRSWi+CHSIXhhVy0VEEpl/Aj2QzeHWc3q+qIgkLP8EejAL56BefXQRSVC+CfQpI/IA2HywxeNKRES84ZtAH1WUSVFWGjX7Fegikph8E+hmxk0jC3j7wAmvSxER8YRvAh1g+qh8GsJnOH6m3etSRESuO38F+sgCAI3SRSQh+SrQp5bmkZxk1CjQRSQB+SrQM9NSmDgsRxdGRSQh+SrQAWaMLGBLYwudkS6vSxERua58F+jTRxVwtj3CrqOnvC5FROS68l+g68KoiCQo3wV6acEQAtnp1BxQH11EEovvAt3MmD4yXzNdRCTh+C7QIdpH3998lvDp816XIiJy3fgy0KtGRfvo6xqaPa5EROT68WWgTyvLJz8zldd3NnldiojIdePLQE9JTuK2CcW8sauJDs1HF5EE4ctAB/jDSSW0nutgw77jXpciInJd+DbQ51cGSUtJ4tUdx7wuRUTkuvBtoGelpzCvIsBrO4/hnPO6HBGRAefbQAe4fVIJB4+fY/cxLQMgIv7n60BfNKEYgFe3q+0iIv7n60Avzs1gWlk+r+5UoIuI//k60CHadtna2MrR1javSxERGVC+D/Q7bhgKwItbD3tciYjIwPJ9oFcUZzNjVAE/fusAXV2a7SIi/uX7QAf42C0j2Rs+w5p6re0iIv6VEIF+5+RhFGSm8qN1+70uRURkwCREoGekJnNvVRmv7jymi6Mi4lsJEegA988aSaTL8dyGg16XIiIyIBIm0EcHsphfGeAn6w/QqRUYRcSHEibQAT52yyiOnmzTgl0i4ku9CnQzW2xmu82szsw+f4nPR5rZm2b2tpltNbO7+r/Uvls0oZhRRZn8+xt1WrBLRHznioFuZsnAfwB3ApOA+81s0rs2+zvgeefcTcB9wH/2d6H9ISU5iU/fVsmOIyd5Reu7iIjP9GaEPguoc841OOfagZ8Cd79rGwfkxr7PAwbtbZkfnDacMYEsvvFarW40EhFf6U2gjwC6Tw1pjL3X3ReBj5lZI/Ay8OlL/SAze8TMNprZxlAodA3l9l1KchKfWVTBrqOneGX7UU9qEBEZCP11UfR+4PvOuVLgLuCHZvZ7P9s597Rzrso5VxUMBvtp11fvAzeOoDyYxTde26NRuoj4Rm8C/RBQ1u11aey97j4JPA/gnFsLZACB/ihwICQnGZ9dVMnuY6d48Z0jXpcjItIvehPoG4BKMxtjZmlEL3oue9c2B4BFAGY2kWige9NT6aX3TR3OxGG5PP7yTs6c7/S6HBGRPrtioDvnOoFHgVeAnURns2w3sy+Z2Qdim/0l8LCZbQF+Aixxg3xeYHKS8eUP3sCR1jaefH2P1+WIiPRZSm82cs69TPRiZ/f3/k+373cAc/u3tIE3Y1Qh/6OqjP9atZcPTy9l/NAcr0sSEblmCXWn6KX89Z0TyM5I4e9/sU03G4lIXEv4QC/MSuPziyewft9xfr6p0etyRESuWcIHOsC9VWXMHF3Al361g8YTZ70uR0TkmijQgaQk4+v3TsMBf/n8FiKamy4icUiBHlNWmMk/vH8Sb+09zndWNnhdjojIVVOgd/ORGaXcOXko//bb3Ww71Op1OSIiV0WB3o2Z8c8fmkJhVhqPPlvDybYOr0sSEek1Bfq7FGSl8X8/Op3GE+f43HNbtNaLiMQNBfolzBxdyBfeO5HXdh7jP5fXeV2OiEivKNB7sGTOaO6eNpx/e7WWFbWDelkaERFAgd4jM+PxD09hfEkOj/64hl1HT3pdkojIZSnQLyMzLYWlS2aSlZ7CA0vXc6jlnNcliYj0SIF+BcPzh/D9P5nJ2fYIS5aup/WsZr6IyOCkQO+FCUNzefrjVexvPsufPLOB01o/XUQGIQV6L80eW8ST909j88EWHvzeeoW6iAw6CvSrsHjyMJ687yZqDkRDXU86EpHBRIF+ld47dRjfvG8aNQdaWPK99bqbVEQGDQX6NXjf1OE8ed9NbD7Ywn3fXkfo1HmvSxIRUaBfq/dOHcZ3H5jJ3vAZ/uipNRw8rnXURcRbCvQ+WDguyI8emsXxM+3c8601bD7Y4nVJIpLAFOh9NGNUIT/70zmkpSRx77fX8ou3D3ldkogkKAV6Pxg/NIdlj87jprJ8/uK5zXzl17v01CMRue4U6P2kMCuNHz10M39880ieWlHPA0vX03xaF0tF5PpRoPej1OQk/ulDU/jqR6ayft9x3v/vq9RXF5HrRoE+AO6tKuOFP5tDUpLxR0+t4dsr6vWgDBEZcAr0ATJ5RB4vfnoeiyaU8Pivd/HxpW9xtLXN67JExMcU6AMoPzONb31sOl/58BRq9rew+JvVvLj1sNdliYhPKdAHmJlx36yRvPSZeYwqyuLRZ9/mU8/WcPxMu9eliYjPKNCvk/JgNv/9p7N57I7x/Hb7Uf7wiRW8tPUIzqm3LiL9Q4F+HaUkJ/GpP6hg2aPzGJY3hE89W8NDz2zUk5BEpF8o0D0wcVgu/+/P5/B3753Imvpmbv/6Cp6urqcj0uV1aSISxxToHklJTuKh+eW8+rkFzBlbxD+/vIu7vrmSNfVhr0sTkTilQPdYaUEm331gJt/9RBVtnRE++p23+PMfb+JAs1ZvFJGrk+J1ARL1nkklzKsM8O0VDTy1op7XdjSxZO5oPvUHFeQNSfW6PBGJAxqhDyIZqcl89j2VvPlXt/KBacP5zsoGbv3amyxdtZf2TvXXReTyFOiD0NC8DP71j27kV4/OY9LwXL704g5uf2IFv9x8SEsIiEiPFOiD2OQRefzokzfz/QdnMiQ1mc/+dDOLv1nNr985omAXkd+jQB/kzIxbxxfz8mfm8+T9N9HZ5fizH9dw15Mr+eXmQ3RqqqOIxJhXdypWVVW5jRs3erLveNYZ6WLZlsP85/J66ppOM7Iwk4cXlPOR6aUMSUv2ujwRGWBmtsk5V3Wpz3o1QjezxWa228zqzOzzPWxzr5ntMLPtZvZsXwqWnqUkJ/Hh6aX89i8W8PTHZ1CYlcbf/2Ibc//lDZ54tVYP1RBJYFccoZtZMlAL3A40AhuA+51zO7ptUwk8D9zmnDthZsXOuabL/VyN0PuHc44N+07wdHUDr+08RlpKEh+aNoIH541mwtBcr8sTkX52uRF6b+ahzwLqnHMNsR/2U+BuYEe3bR4G/sM5dwLgSmEu/cfMmDWmkFljCqlrOs331+zl55saeW7jQWaXF/Hx2aO4fVIJqcm6XCLid735v3wEcLDb68bYe92NA8aZ2WozW2dmiy/1g8zsETPbaGYbQ6HQtVUsPaoozubLH5zCur9ZxF8vnsCB42f58x/XMPcrb/D1V2u1CJiIz/Wm5fIRYLFz7qHY648DNzvnHu22zYtAB3AvUApUA1Occz0+UFMtl4EX6XIs393ED9ftZ0Vt9B/QW8cFuW/WSG6bUKxRu0gc6mvL5RBQ1u11aey97hqBt5xzHcBeM6sFKon228UjyUnGooklLJpYwsHjZ3l+40Ge23CQ//nDTQSy07lnxgjurSpjbDDb61JFpB/0ZoSeQvSi6CKiQb4B+Khzbnu3bRYTvVD6gJkFgLeBac655p5+rkbo3uiMdLF8d4ifbjjIm7ubiHQ5po/M5yMzynjv1GFaN0ZkkLvcCL1X89DN7C7gG0AysNQ5909m9iVgo3NumZkZ8G/AYiAC/JNz7qeX+5kKdO81nWzjhbcP8d+bGtnTdJq0lCTeM7GYD04bwa3ji0lLUUtGZLDpc6APBAX64OGcY2tjKy/UNPLi1iM0n2knb0gqd04eyvumDueW8kJS1G8XGRQU6NJrHZEuVtWFWbb5ML/dfpQz7REC2WncNWUY779xODNGFpCUZF6XKZKwFOhyTdo6Iizf3cSyLYd5fWcT5zu7GJaXwZ2Th3HXlKFMV7iLXHcKdOmz0+c7eX3nMX615TDVtWHaI12U5Kaz+Iah3DllGDNHF5KscBcZcAp06Ven2jp4Y1cTL79zhOW7Q5zv7CKQnc7tk4q5fVIJc8YGyEjVQmEiA0GBLgPmzPlO3tzdxK/fOcry3U2caY+QmZbMgsog75lUwh+MD1KUne51mSK+0dcbi0R6lJWewvumDud9U4dzvjPC2vpmXt1xjNd2HuM324+SZDB9ZAGLJpbwnonFVBRnE53lKiL9TSN0GRDOObYdOsmrO4/x+s5jbD98EoCRhZncNqGY2yYUc3N5Iekpas2IXA21XMRzR1rP8frOJt7Y1cTqujDnO7sYkprMnLFFLBwfZOG4IKOKsrwuU2TQU6DLoHKuPcKa+jArakMs3x3iwPGzQHT0Pr8ywPzKILPHFmkZApFLUKDLoOWcY1/zWVbuCVFdG2JtfTNn2iMkGUwry2d+ZZBbxweZWpqvaZEiKNAljrR3dvH2gROsqgtTvSfM1sYWnIPCrDQWVAaYVxlkXkWAoXkZXpcq4gkFusStE2faqd4Tbc1U14ZoPtMORB/mMa8iwPzKADeXF5GdrglbkhgU6OILXV2OXUdPsbouzMq6MOv3NtPW0UVKkjF9ZAFzKwLMqwxwY2meFhMT31Kgiy+1dUTYtP8EK/eEWV0XZtvhVpyD7PQUZo0pZM7YIuZWBBhfkqM1Z8Q3dGOR+FJGajJzKwLMrQgA0fbM2oZmVteFWVPfzBu7os8qL8pKY05FgDlji5hdXsSookzd3CS+pBG6+NbhlnMXw31VXZjQqfMADM/L4JaxRcwZG2BuRRHD8oZ4XKlI76nlIgnPOUd96AxrG5pZWx9mbX0zJ852ADAmkMWcWMDPHltEYVaax9WK9EyBLvIuFy6wrqmPjuDfaojOfweYNCyXuRXR/vvNY4oYkqblCWTwUKCLXEFHpIutjS2sqWtmdX2Ymv0ttEe6SEtOYuaYAuZXBplfGWDSsFz138VTCnSRq3SuPcKGfcdZuSfEyj1hdh09BUAgO50FlQHmj4tejC3O0Q1Ocn1plovIVRqSlsyCcUEWjAsCcOxkG9W1Iar3hHlzdxMvvH0IgAlDc6Lz3ysCzBpTSJZucBIPaYQucpW6uhw7jpxk5Z4wq+pCbNh3gvbO2A1OowouLlEwZUSe1p+RfqeWi8gA6n6D06q6ENsORdd+z8lI4eYxRcwZW8T8yoAe7iH9Qi0XkQH0uzc4TSB8+jyr68Ksa2hmbX0zr+08BsDQ3AzmVUbXn5lbESCgR/NJP9MIXWSANZ44y6o90fVnVteFaYnNf584LJe5seUJ1H+X3lLLRWSQiHQ5th1qZVVdmJV7QhenR6YkGdPK8i8uUXDTyHw9nk8uSYEuMki1dUTYuO8Eq2M3OL3T2EKXgyGpydxcXsi8igALxgWpVP9dYhToInGi9VwHb8UWGFtZF6YhdAaIrj+zcHwxt44PMmdsETkZejxfolKgi8Spwy3nYs9ebWLVnjBn2iMkJxnTR+azoDI6T36ypkcmFAW6iA+0d3ZRc+BE7PmrYd451ApAQWYq8yqD3Bq7ESqYo9kzfqZAF/Gh5tPnWVUXZkVtNODDp6PLA98wPDd6l2tlkBmjCkhL0dOb/ESBLuJzF+5eXVEbYkVtiJr9J+jscmSmJXNLeVFs/Zkg5YEsXVyNcwp0kQRzqq2DdQ3Hqa4NsXJPiH3NZwEoKxzCwnFBFo4rZvZYPVw7HinQRRLcgeazrNgTYsXuEGvqw5xtj5CabMwYVcDCccUsHBdk4rAcjd7jgAJdRC5q7+xi477jFwP+wtLAwZz02MyZAPMrg3py0yClQBeRHl1YGnhFbYhVsaUJzGBqaT4LY733aWX5pCbr4upgoEAXkV6JdDm2NrZQXRtmRW0Tmw9G71zNSU9hTkURC8cVs2BcgNKCTK9LTVgKdBG5Jq3nOlhTF6Y61p453NoGwNhgFgvGBVk4Lsgt5UVkpGrdmetFgS4ifeacoz50muW7o+2Zt/Yep72zi/SUJG4uL4rNngkyNqipkQOpz4FuZouBbwLJwHedc1/pYbt7gJ8DM51zl01rBbpIfGvriLCuoflie6Y+tu5MWeEQbh0XXXdm9tgiMtM0NbI/9SnQzSwZqAVuBxqBDcD9zrkd79ouB3gJSAMeVaCLJJaDx8+yvDbEit1NrK5r5lxHhLTkJGaOKWBBZZCF44OML9HUyL7qa6DPBr7onLsj9vpvAJxzj79ru28ArwKPAX+lQBdJXBeWBb7Qe999LDo1siQ3/WK4z6sIkJ+pqZFXq6+PoBsBHOz2uhG4+V07mA6UOedeMrPHLlPII8AjACNHjuzFrkUkHmWkJjOvMsC8ygB/e9dEjrSeY2VtdN2ZV7Yf5WebGkkymFaWz8JYe2bKiDyStGpkn/S5uWVmScDXgSVX2tY59zTwNERH6H3dt4jEh2F5Q7h3Zhn3ziyjM9LFlsZWVuxuYkVtiG+8XssTr9VSmJXG3IoA8yui/xAMzx/iddlxpzeBfggo6/a6NPbeBTnAZGB5rDc2FFhmZh+4UttFRBJPSnISM0YVMGNUAZ/7w/GET59nZaw1s7q+mV9tOQzAuJJsFo4Lcuv4YqpGF+iRfL3Qmx56CtGLoouIBvkG4KPOue09bL8c9dBF5Bo456g9dvrinavr9x6nPdJFZloys8uLWDg+OjVyVFGW16V6pk89dOdcp5k9CrxCdNriUufcdjP7ErDRObesf8sVkURlZowfmsP4oTk8vKCcM+c7WVvfTPWeEMt3h3h9VxMAo4oyoxdXx0WnRmZp1UhANxaJSBzZGz5DdW2I6toQaxuaL64aWTWq8OLofcJQf0+N1J2iIuI75zsjbNp34vdWjSzJTWd+7Hmr8yoCvls1UoEuIr53tLXt4rz3VXVhWs9FV42cMiKPeRXRJYH98Eg+BbqIJJTuq0auqgtRc6CFSLdH8s2vDDCvIkBFcXbctWcU6CKS0E61dbCmvplVe8KsqguzNxxddyaYk86csUXR+e+VAYblDf657329U1REJK7lZKRyxw1DueOGoUB03ZnVdWFW1zezui7MLzdH575XFmcztyLA7LFF3DKmiLzMVC/LvmoaoYtIQnPOsevoKVbuCbFyT5j1e49zvrMLM5g0LJe5FQHmjC1i1pjCQbFypFouIiK9dL4zwpaDraytb2ZNfZiaAyfoiDhSkoyppXncXB4N96pRBeRkXP8RvAJdROQanWuPsGHfcdbUN7N+bzNbG1vp7HIkGUwekces0YXMjAV8UXb6gNejQBcR6Sdn2zup2d/C+r3NrNt7nM0HW2jv7AKgPJjFjJEFTB9VwPSRBVQUZ5PczytI6qKoiEg/yUxLubg0METXft92qJUN+06wcd9xXtt5jJ9tagQgOz2FKSPymDYyn2ll0a+S3IwBq02BLiLSBxmpyVSNLqRqdCEwFucc+5rPUrP/BJsPtrD5YAvfqW6gsyvaDRmWl8Hn75zA3dNG9HstCnQRkX5kZowJZDEmkMU9M0qB6Ch+++GTbIkFfDBnYHrtCnQRkQGWkZp8cQ34gRTfixqIiMhFCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE8o0EVEfMKzxbnMLATsv4o/EgDCA1TOYJaIx52IxwyJedyJeMzQt+Me5ZwLXuoDzwL9apnZxp5WGPOzRDzuRDxmSMzjTsRjhoE7brVcRER8QoEuIuIT8RToT3tdgEcS8bgT8ZghMY87EY8ZBui446aHLiIilxdPI3QREbkMBbqIiE/ERaCb2WIz221mdWb2ea/rGQhmVmZmb5rZDjPbbmafjb1faGavmtme2H8HdoV8D5hZspm9bWYvxl6PMbO3Yuf7OTNL87rG/mZm+Wb2czPbZWY7zWx2gpzr/xX7+73NzH5iZhl+O99mttTMmsxsW7f3LnluLerJ2LFvNbPpfdn3oA90M0sG/gO4E5gE3G9mk7ytakB0An/pnJsE3AJ8Knacnwded85VAq/HXvvNZ4Gd3V7/C/CEc64COAF80pOqBtY3gd845yYANxI9fl+fazMbAXwGqHLOTQaSgfvw3/n+PrD4Xe/1dG7vBCpjX48A3+rLjgd9oAOzgDrnXINzrh34KXC3xzX1O+fcEedcTez7U0T/Bx9B9FifiW32DPBBbyocGGZWCrwX+G7stQG3AT+PbeLHY84DFgD/BeCca3fOteDzcx2TAgwxsxQgEziCz863c64aOP6ut3s6t3cDP3BR64B8Mxt2rfuOh0AfARzs9rox9p5vmdlo4CbgLaDEOXck9tFRoMSjsgbKN4D/DXTFXhcBLc65zthrP57vMUAI+F6s1fRdM8vC5+faOXcI+FfgANEgbwU24f/zDT2f237Nt3gI9IRiZtnAfwN/4Zw72f0zF51j6pt5pmb2PqDJObfJ61qusxRgOvAt59xNwBne1V7x27kGiPWN7yb6D9pwIIvfb0343kCe23gI9ENAWbfXpbH3fMfMUomG+Y+dcy/E3j524Vew2H+bvKpvAMwFPmBm+4i20m4j2lvOj/1KDv48341Ao3PurdjrnxMNeD+fa4D3AHudcyHnXAfwAtG/A34/39Dzue3XfIuHQN8AVMauhKcRvYiyzOOa+l2sd/xfwE7n3Ne7fbQMeCD2/QPAL693bQPFOfc3zrlS59xoouf1DefcHwNvAh+JbearYwZwzh0FDprZ+Nhbi4Ad+PhcxxwAbjGzzNjf9wvH7evzHdPTuV0GfCI22+UWoLVba+bqOecG/RdwF1AL1ANf8LqeATrGeUR/DdsKbI593UW0p/w6sAd4DSj0utYBOv5bgRdj35cD64E64GdAutf1DcDxTgM2xs73L4CCRDjXwPnnmqcAAABbSURBVD8Cu4BtwA+BdL+db+AnRK8RdBD9beyTPZ1bwIjO4qsH3iE6A+ia961b/0VEfCIeWi4iItILCnQREZ9QoIuI+IQCXUTEJxToIiI+oUAXEfEJBbqIiE/8f8tHyw/7ty6lAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy\n",
        "history_df.plot(y=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3vf1V5_6_0GE",
        "outputId": "27938880-e485-4737-ca8a-ce697c4c1bb6"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb507fc0ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create the Connective Tissue, the Multiple Neuron Neutral Network**"
      ],
      "metadata": {
        "id": "Tg3XoFPJAqj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advantages for adding neurons to our hidden layer in a neural network :\n",
        "### 1: there is a distributed effort to find optimal weights - faster\n",
        "### 2: each neuron can focus on different features to identify nonlinear effects - smarter\n",
        "### 3: it is less likely to fixate on complex variables - more robust\n",
        "\n",
        "\n",
        "\n",
        "## Two main reasons to limit the number of neurons in a neural network model : overfitting and computation resources \n",
        "### overfitting: the neural network will not generalize well and won't be able to classify new data correctly \n",
        "### a neural network model with a large number of neurons requires equally large training dataset- training a large neural network requires more data, more epochs and more time.\n",
        "\n",
        "## A good rule of thumb for a basic neural network is to have two to three times the amount of neurons in the hidden layer as the number of inputs."
      ],
      "metadata": {
        "id": "Lv_mshtpA57k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since we want to change the structure of our neural network model , we first create a new sequential model \n",
        "\n",
        "# generage our nre sequential model\n",
        "new_model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "qNs0WJz0CoYj"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we want to use 6 neurons by changeing the units parameter\n",
        "\n",
        "# Add the input and hidden layer\n",
        "number_inputs = 2\n",
        "number_hidden_nodes = 6\n",
        "\n",
        "new_model.add(tf.keras.layers.Dense(units=number_hidden_nodes, activation=\"relu\", input_dim=number_inputs))\n",
        "\n",
        "# Add the output layer that uses a probability activation function\n",
        "new_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "BiMV0VmHDQK6"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Sequential model together and customize metrics\n",
        "new_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model to the training data\n",
        "new_fit_model = new_model.fit(X_moon_train_scaled, y_moon_train, epochs=100, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ptT76pDifi",
        "outputId": "7cf58707-0633-4b0e-cfd5-709c4ea08432"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.9550 - accuracy: 0.4680\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8930 - accuracy: 0.4933\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.8367 - accuracy: 0.5120\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7859 - accuracy: 0.5387\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7392 - accuracy: 0.5813\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.6267\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6720\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.7120\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.7533\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7613\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7747\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7933\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7973\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8133\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8200\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8307\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8387\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8427\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8453\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8467\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8493\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8573\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8640\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8680\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8733\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8760\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8787\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8827\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2987 - accuracy: 0.8840\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2953 - accuracy: 0.8840\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.8853\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8853\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8867\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8867\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8867\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.8867\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8880\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2764 - accuracy: 0.8893\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2751 - accuracy: 0.8893\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.8893\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2723 - accuracy: 0.8907\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.8893\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.8893\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2686 - accuracy: 0.8893\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8893\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8893\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2659 - accuracy: 0.8893\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8893\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8893\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8893\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2627 - accuracy: 0.8893\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2621 - accuracy: 0.8893\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.8907\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.8907\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.8907\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2596 - accuracy: 0.8907\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8907\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.8907\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2578 - accuracy: 0.8893\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2572 - accuracy: 0.8893\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2565 - accuracy: 0.8893\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.8893\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.8893\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.8907\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.8907\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.8893\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8907\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.8907\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2521 - accuracy: 0.8907\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 0.8920\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2511 - accuracy: 0.8907\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.8920\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2505 - accuracy: 0.8920\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8947\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.8947\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8947\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.8933\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8947\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.8947\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8947\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8947\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8947\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8947\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8947\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8947\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8960\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8960\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8960\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8960\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8960\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8960\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8960\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8960\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8973\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.8973\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8973\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8973\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8973\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8973\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.8973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### by looking the output above, we increase the number of neurons within the hidden layer, the classification accuracy improves. "
      ],
      "metadata": {
        "id": "3Ysf4qoNDqZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing**"
      ],
      "metadata": {
        "id": "uIriT6EfPyZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Categorical Variables**\n",
        "\n",
        "### preprocess the values using a technique called \n",
        "### **one-hot encoding** : identifies all unique column values and split the single categorical column into a series of columns, each containing info about a single unique categorical value. \n",
        "\n",
        "### categorical variables with a large number of unique values might become difficult to navigate or filter once encoded. then we must reduce the number of unique values in the categorical variables. the precess is called **bucketing** or **binning**. bucketing data typically follows one of two approaches:\n",
        "#### 1. collapse all of the infrequent and rare categorical values into a single 'other' category\n",
        "#### 2. create generalized categorical values and reassign all data points to the new corresponding values.\n",
        "\n"
      ],
      "metadata": {
        "id": "BfpvElbYYvUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Practice**"
      ],
      "metadata": {
        "id": "nn1o9I6Ubu-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our dependencies\n",
        "import pandas as pd\n",
        "import sklearn as skl\n",
        "\n",
        "# Read in our ramen data\n",
        "ramen_df = pd.read_csv(\"ramen-ratings.csv\")\n",
        "\n",
        "# Print out the Country value counts\n",
        "country_counts = ramen_df.Country.value_counts()\n",
        "country_counts\n",
        "\n",
        "# in a hypothetical scenario, we need to use the 'country' variable as a categorical variable in a large dataset that will predict restaurant satisfication\n",
        "# before we convert country into a one-hot encoding, we need to make sure that there are not too many unique values\n",
        "# we need to check for unique values is to use the pd dataframe's value_counts method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8zviobybzyE",
        "outputId": "ebf93489-89c1-4576-dccb-7ea7df9bd57b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Japan            352\n",
              "USA              323\n",
              "South Korea      309\n",
              "Taiwan           224\n",
              "Thailand         191\n",
              "China            169\n",
              "Malaysia         156\n",
              "Hong Kong        137\n",
              "Indonesia        126\n",
              "Singapore        109\n",
              "Vietnam          108\n",
              "UK                69\n",
              "Philippines       47\n",
              "Canada            41\n",
              "India             31\n",
              "Germany           27\n",
              "Mexico            25\n",
              "Australia         22\n",
              "Netherlands       15\n",
              "Myanmar           14\n",
              "Nepal             14\n",
              "Pakistan           9\n",
              "Hungary            9\n",
              "Bangladesh         7\n",
              "Colombia           6\n",
              "Brazil             5\n",
              "Cambodia           5\n",
              "Fiji               4\n",
              "Holland            4\n",
              "Poland             4\n",
              "Finland            3\n",
              "Sarawak            3\n",
              "Sweden             3\n",
              "Dubai              3\n",
              "Ghana              2\n",
              "Estonia            2\n",
              "Nigeria            1\n",
              "United States      1\n",
              "Name: Country, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how do we determine which countries are uncommon enough to bucket into the 'other' categoru?\n",
        "# most straightforward method is to use a density plot to identify where the value counts 'fall off' and set the threshold within this region\n",
        "\n",
        "# visualize the value counts\n",
        "country_counts.plot.density()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "yIioJqjXfUUY",
        "outputId": "2a039097-7725-42ba-d2dd-5acaea1c8eee"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb503c09d90>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### According to the density plot, the most common unique values have more than 100 instances within the dataset. Therefore, we can bucket any country that appears fewer than 100 times in the dataset as \"other.\" To do this, we'll use a Python for loop and Pandas' replace method. "
      ],
      "metadata": {
        "id": "Bl0u9ub5fWf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# determine which values to replace\n",
        "replace_countries = list(country_counts[country_counts < 100].index)\n",
        "\n",
        "# replace in DataFrame\n",
        "for country in replace_countries:\n",
        "    ramen_df.Country = ramen_df.Country.replace(country,'Other')\n",
        "    \n",
        "# check to make sure binning was successful\n",
        "ramen_df.Country.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn-7l64zfp8G",
        "outputId": "7a2172d5-2f33-4318-8df8-739024005ddf"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other          376\n",
              "Japan          352\n",
              "USA            323\n",
              "South Korea    309\n",
              "Taiwan         224\n",
              "Thailand       191\n",
              "China          169\n",
              "Malaysia       156\n",
              "Hong Kong      137\n",
              "Indonesia      126\n",
              "Singapore      109\n",
              "Vietnam        108\n",
              "Name: Country, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now we are ready to transpose the variable using one-hot encoding. we use scikit-learn's OneHotEncoder module on the country variable"
      ],
      "metadata": {
        "id": "2AeXwkh5fu2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the onehotencoder instance\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# fit the encoder and produce encoded DataFrame\n",
        "encode_df = pd.DataFrame(enc.fit_transform(ramen_df.Country.values.reshape(-1,1)))\n",
        "\n",
        "# rename encoded columns\n",
        "encode_df.columns = enc.get_feature_names(['Country'])\n",
        "encode_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "cz9e1S8Df7AS",
        "outputId": "527157d3-4cc6-48e8-e1e0-37392f634fa4"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-189f3f31-324d-4cde-992c-e11392a3c46a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country_China</th>\n",
              "      <th>Country_Hong Kong</th>\n",
              "      <th>Country_Indonesia</th>\n",
              "      <th>Country_Japan</th>\n",
              "      <th>Country_Malaysia</th>\n",
              "      <th>Country_Other</th>\n",
              "      <th>Country_Singapore</th>\n",
              "      <th>Country_South Korea</th>\n",
              "      <th>Country_Taiwan</th>\n",
              "      <th>Country_Thailand</th>\n",
              "      <th>Country_USA</th>\n",
              "      <th>Country_Vietnam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-189f3f31-324d-4cde-992c-e11392a3c46a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-189f3f31-324d-4cde-992c-e11392a3c46a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-189f3f31-324d-4cde-992c-e11392a3c46a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Country_China  Country_Hong Kong  ...  Country_USA  Country_Vietnam\n",
              "0            0.0                0.0  ...          0.0              0.0\n",
              "1            0.0                0.0  ...          0.0              0.0\n",
              "2            0.0                0.0  ...          1.0              0.0\n",
              "3            0.0                0.0  ...          0.0              0.0\n",
              "4            0.0                0.0  ...          0.0              0.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### then we must join the encoded dataframe with the original and drop the original country column. we use merge method"
      ],
      "metadata": {
        "id": "UKtMf5d-gleQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the two dataframes together and drop the country column\n",
        "ramen_df.merge(encode_df, left_index = True, right_index=True).drop('Country',1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_Cdmcjdgto9",
        "outputId": "00f7daf9-09fe-474d-ad0a-a93906802e1b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a071f10-4e3d-4f2f-ad04-abd27663bebe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review #</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Variety</th>\n",
              "      <th>Style</th>\n",
              "      <th>Stars</th>\n",
              "      <th>Top Ten</th>\n",
              "      <th>Country_China</th>\n",
              "      <th>Country_Hong Kong</th>\n",
              "      <th>Country_Indonesia</th>\n",
              "      <th>Country_Japan</th>\n",
              "      <th>Country_Malaysia</th>\n",
              "      <th>Country_Other</th>\n",
              "      <th>Country_Singapore</th>\n",
              "      <th>Country_South Korea</th>\n",
              "      <th>Country_Taiwan</th>\n",
              "      <th>Country_Thailand</th>\n",
              "      <th>Country_USA</th>\n",
              "      <th>Country_Vietnam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2580</td>\n",
              "      <td>New Touch</td>\n",
              "      <td>T's Restaurant Tantanmen</td>\n",
              "      <td>Cup</td>\n",
              "      <td>3.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2579</td>\n",
              "      <td>Just Way</td>\n",
              "      <td>Noodles Spicy Hot Sesame Spicy Hot Sesame Guan...</td>\n",
              "      <td>Pack</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2578</td>\n",
              "      <td>Nissin</td>\n",
              "      <td>Cup Noodles Chicken Vegetable</td>\n",
              "      <td>Cup</td>\n",
              "      <td>2.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2577</td>\n",
              "      <td>Wei Lih</td>\n",
              "      <td>GGE Ramen Snack Tomato Flavor</td>\n",
              "      <td>Pack</td>\n",
              "      <td>2.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576</td>\n",
              "      <td>Ching's Secret</td>\n",
              "      <td>Singapore Curry</td>\n",
              "      <td>Pack</td>\n",
              "      <td>3.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>5</td>\n",
              "      <td>Vifon</td>\n",
              "      <td>Hu Tiu Nam Vang [\"Phnom Penh\" style] Asian Sty...</td>\n",
              "      <td>Bowl</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2576</th>\n",
              "      <td>4</td>\n",
              "      <td>Wai Wai</td>\n",
              "      <td>Oriental Style Instant Noodles</td>\n",
              "      <td>Pack</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2577</th>\n",
              "      <td>3</td>\n",
              "      <td>Wai Wai</td>\n",
              "      <td>Tom Yum Shrimp</td>\n",
              "      <td>Pack</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2578</th>\n",
              "      <td>2</td>\n",
              "      <td>Wai Wai</td>\n",
              "      <td>Tom Yum Chili Flavor</td>\n",
              "      <td>Pack</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2579</th>\n",
              "      <td>1</td>\n",
              "      <td>Westbrae</td>\n",
              "      <td>Miso Ramen</td>\n",
              "      <td>Pack</td>\n",
              "      <td>0.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2580 rows  18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a071f10-4e3d-4f2f-ad04-abd27663bebe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a071f10-4e3d-4f2f-ad04-abd27663bebe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a071f10-4e3d-4f2f-ad04-abd27663bebe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Review #           Brand  ... Country_USA Country_Vietnam\n",
              "0         2580       New Touch  ...         0.0             0.0\n",
              "1         2579        Just Way  ...         0.0             0.0\n",
              "2         2578          Nissin  ...         1.0             0.0\n",
              "3         2577         Wei Lih  ...         0.0             0.0\n",
              "4         2576  Ching's Secret  ...         0.0             0.0\n",
              "...        ...             ...  ...         ...             ...\n",
              "2575         5           Vifon  ...         0.0             1.0\n",
              "2576         4         Wai Wai  ...         0.0             0.0\n",
              "2577         3         Wai Wai  ...         0.0             0.0\n",
              "2578         2         Wai Wai  ...         0.0             0.0\n",
              "2579         1        Westbrae  ...         1.0             0.0\n",
              "\n",
              "[2580 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Standardization**"
      ],
      "metadata": {
        "id": "CsBP64k5jDlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## there are many reasons why a raw numeric variable is insufficient for use when training a neural network model:\n",
        "### 1. raw data often has outliers or extreme values that can artifically inflate a variable's importance\n",
        "### 2. numerical data can be measured using different units across a dataset such as time vs temperature or length vs volume\n",
        "### 3. the distribution of a variable can be skewed, leading to misinterpretation of the central tendency\n",
        "\n",
        "## there is a great probability that the neural network model will interpret the raw numerical data inappropriately. \n",
        "\n",
        "## So! we should minimize this risk by standardizing (AKA normalization) the numerical data prior to training"
      ],
      "metadata": {
        "id": "fLRBk2UsjVdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standardization Practice\n",
        "\n",
        "### If we use the StandardScaler module to standardize our numerical variables, we reduce the overall likelihood that outliers, variables of different units or skewed distributions will have a negative impact on model's performance"
      ],
      "metadata": {
        "id": "vf1tgvwclHlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our dependencies\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read in our dataset\n",
        "hr_df = pd.read_csv(\"hr_dataset.csv\")\n",
        "hr_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tWCA_nCRluOr",
        "outputId": "4be0f57b-b8d3-440b-d4fe-9cf2313722c4"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0ffd6dc3-13d7-4599-be46-d9addce99fb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Satisfaction_Level</th>\n",
              "      <th>Num_Projects</th>\n",
              "      <th>Time_Spent</th>\n",
              "      <th>Num_Promotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.30</td>\n",
              "      <td>1</td>\n",
              "      <td>253</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.90</td>\n",
              "      <td>4</td>\n",
              "      <td>2880</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.65</td>\n",
              "      <td>3</td>\n",
              "      <td>1450</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.50</td>\n",
              "      <td>2</td>\n",
              "      <td>785</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ffd6dc3-13d7-4599-be46-d9addce99fb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ffd6dc3-13d7-4599-be46-d9addce99fb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ffd6dc3-13d7-4599-be46-d9addce99fb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Satisfaction_Level  Num_Projects  Time_Spent  Num_Promotions\n",
              "0                0.30             1         253               2\n",
              "1                0.25             1         200               0\n",
              "2                0.90             4        2880               5\n",
              "3                0.65             3        1450               3\n",
              "4                0.50             2         785               2"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the standardscaler instance\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "wBlhknYql3t5"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the standardscaler\n",
        "scaler.fit(hr_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF3P5M5Ql88W",
        "outputId": "5b63aa6b-fd83-4fb3-f057-7d4cbcdcd81b"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the data\n",
        "scaled_data = scaler.transform(hr_df)"
      ],
      "metadata": {
        "id": "Z5MpM_tAmEk1"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe with the scaled data\n",
        "transformed_scaled_data = pd.DataFrame(scaled_data, columns = hr_df.columns)\n",
        "transformed_scaled_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9WAgqqmhmKmm",
        "outputId": "c14ea617-674a-48a4-ca17-d4a45c15a239"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fd08d087-452b-441f-9459-ca501083a339\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Satisfaction_Level</th>\n",
              "      <th>Num_Projects</th>\n",
              "      <th>Time_Spent</th>\n",
              "      <th>Num_Promotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.303615</td>\n",
              "      <td>-1.162476</td>\n",
              "      <td>-1.049481</td>\n",
              "      <td>-0.558656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.512945</td>\n",
              "      <td>-1.162476</td>\n",
              "      <td>-1.094603</td>\n",
              "      <td>-1.804887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.208335</td>\n",
              "      <td>0.860233</td>\n",
              "      <td>1.187080</td>\n",
              "      <td>1.310692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.161689</td>\n",
              "      <td>0.185996</td>\n",
              "      <td>-0.030385</td>\n",
              "      <td>0.064460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.466299</td>\n",
              "      <td>-0.488240</td>\n",
              "      <td>-0.596549</td>\n",
              "      <td>-0.558656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd08d087-452b-441f-9459-ca501083a339')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd08d087-452b-441f-9459-ca501083a339 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd08d087-452b-441f-9459-ca501083a339');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Satisfaction_Level  Num_Projects  Time_Spent  Num_Promotions\n",
              "0           -1.303615     -1.162476   -1.049481       -0.558656\n",
              "1           -1.512945     -1.162476   -1.094603       -1.804887\n",
              "2            1.208335      0.860233    1.187080        1.310692\n",
              "3            0.161689      0.185996   -0.030385        0.064460\n",
              "4           -0.466299     -0.488240   -0.596549       -0.558656"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### all of the variables have now been standardized with mean value of 0 and standard deviation of 1. Now the data is ready to be passed along to our neural network model"
      ],
      "metadata": {
        "id": "8pmknsco20hd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning Models**\n",
        "\n",
        "## there are limitations to using a basic neural network such as : \n",
        "\n",
        "### 1. a basic neural network with many neurons will require more training data than other comparable statistics and machine learning models to produce an adequate model\n",
        "\n",
        "### 2. basic neural networks struggle to interpret complex nonlinear numerical data or data with many confounding factors that have hidden effects on more than one variabale\n",
        "\n",
        "### 3. basic neural networks are incapable of analyzing image datasets without severe data preprocessing.\n",
        "\n",
        "\n",
        "## to address the limations of the basic neural network, we can implement a more robust neural network model by adding additional hidden layers. \n",
        "\n",
        "## a neural network with more than one hidden layer is known as **deep neural network** or commonly referred to as **deep learning models**\n",
        "\n",
        "## the next layer of neurons can evaluate higher order interactions between weighted variables and identify complex, nonlinear relationships across the entire dataset. The additional layers can identify and account for more information than any number of neurons in a single hidden layer.\n",
        "\n",
        "## **deep learning models** can identify patterns, determine severity and adapt to changing input data from a wide variety of data sources. compared to basic neural network models, deep learning models only need a few neurons across a few hidden layers to identify the same nonlinear characteristics.\n",
        "\n",
        "## **deep learning models** can train on images, natural language data, soundwaves and traditional tabular data(data that fits in a table or DataFrame, all with minimal preprocessing and directions"
      ],
      "metadata": {
        "id": "MlCM8ODk3bMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Model Practice"
      ],
      "metadata": {
        "id": "K-iOh-jg7PZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import our input dataset\n",
        "attrition_df = pd.read_csv('HR-Employee-Attrition.csv')\n",
        "attrition_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "Yc9JJpJZAOfq",
        "outputId": "37646756-15bd-4bd1-9dd9-b8c2e9a5e9f0"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-473f8445-d8c1-4e39-902e-7d28ae622101\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>Over18</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1102</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Sales Executive</td>\n",
              "      <td>4</td>\n",
              "      <td>Single</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>279</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1373</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Male</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3</td>\n",
              "      <td>Single</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>1392</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>Y</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>591</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-473f8445-d8c1-4e39-902e-7d28ae622101')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-473f8445-d8c1-4e39-902e-7d28ae622101 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-473f8445-d8c1-4e39-902e-7d28ae622101');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Age Attrition  ... YearsSinceLastPromotion  YearsWithCurrManager\n",
              "0   41       Yes  ...                       0                     5\n",
              "1   49        No  ...                       1                     7\n",
              "2   37       Yes  ...                       0                     0\n",
              "3   33        No  ...                       3                     0\n",
              "4   27        No  ...                       2                     2\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### there are multiple columns with categorical values as well as our numerical value. To make things easier, we should generate a list of categorical variable names. "
      ],
      "metadata": {
        "id": "VQVZJR02AjUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate our categorical variable list\n",
        "attrition_cat = attrition_df.dtypes[attrition_df.dtypes=='object'].index.tolist()\n",
        "attrition_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3qLPbUpA1kX",
        "outputId": "ad527f26-82c8-4349-f464-111fbb23c148"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Attrition',\n",
              " 'BusinessTravel',\n",
              " 'Department',\n",
              " 'EducationField',\n",
              " 'Gender',\n",
              " 'JobRole',\n",
              " 'MaritalStatus',\n",
              " 'Over18',\n",
              " 'OverTime']"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we have our variable names sperated, we can start to preprocess our data starting with the one-hot encoding of the categorical data. looking at our attrition_cat, there are 8 categorical variables that need encoding. before using the scikit-learn's OneHotEncoder, we need to make asure that none of the categorical variables have more than 10 unique values and require bucketing\n"
      ],
      "metadata": {
        "id": "Z31Ll79WBK-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the number of unique values in each column\n",
        "attrition_df[attrition_cat].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_TCp6HYBnLK",
        "outputId": "8ceaf340-1f97-4f47-d03b-b0d6e09d131d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Attrition         2\n",
              "BusinessTravel    3\n",
              "Department        3\n",
              "EducationField    6\n",
              "Gender            2\n",
              "JobRole           9\n",
              "MaritalStatus     3\n",
              "Over18            1\n",
              "OverTime          2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse = False)\n",
        "\n",
        "# fit and transform the OneHotEncoder useing the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(attrition_df[attrition_cat]))\n",
        "\n",
        "# add the encoded variable names to the DataFrame\n",
        "encode_df.columns = enc.get_feature_names(attrition_cat)\n",
        "encode_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "c75iqjq3B1vP",
        "outputId": "cc0c3507-c571-468a-8724-076de629317c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d043930a-695a-4418-8650-75bce89a2bec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attrition_No</th>\n",
              "      <th>Attrition_Yes</th>\n",
              "      <th>BusinessTravel_Non-Travel</th>\n",
              "      <th>BusinessTravel_Travel_Frequently</th>\n",
              "      <th>BusinessTravel_Travel_Rarely</th>\n",
              "      <th>Department_Human Resources</th>\n",
              "      <th>Department_Research &amp; Development</th>\n",
              "      <th>Department_Sales</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>JobRole_Healthcare Representative</th>\n",
              "      <th>JobRole_Human Resources</th>\n",
              "      <th>JobRole_Laboratory Technician</th>\n",
              "      <th>JobRole_Manager</th>\n",
              "      <th>JobRole_Manufacturing Director</th>\n",
              "      <th>JobRole_Research Director</th>\n",
              "      <th>JobRole_Research Scientist</th>\n",
              "      <th>JobRole_Sales Executive</th>\n",
              "      <th>JobRole_Sales Representative</th>\n",
              "      <th>MaritalStatus_Divorced</th>\n",
              "      <th>MaritalStatus_Married</th>\n",
              "      <th>MaritalStatus_Single</th>\n",
              "      <th>Over18_Y</th>\n",
              "      <th>OverTime_No</th>\n",
              "      <th>OverTime_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d043930a-695a-4418-8650-75bce89a2bec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d043930a-695a-4418-8650-75bce89a2bec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d043930a-695a-4418-8650-75bce89a2bec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Attrition_No  Attrition_Yes  ...  OverTime_No  OverTime_Yes\n",
              "0           0.0            1.0  ...          0.0           1.0\n",
              "1           1.0            0.0  ...          1.0           0.0\n",
              "2           0.0            1.0  ...          0.0           1.0\n",
              "3           1.0            0.0  ...          0.0           1.0\n",
              "4           1.0            0.0  ...          1.0           0.0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge one-hot encoded features and drop the originals\n",
        "attrition_df = attrition_df.merge(encode_df, left_index = True, right_index = True)\n",
        "attrition_df = attrition_df.drop(attrition_cat,1)\n",
        "attrition_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "ILrDRmI-Ca9I",
        "outputId": "2c73cbb0-e106-4d57-dd66-9863bb1eeabf"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45c3b8f2-3a18-43af-9af9-ec403c7731fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition_No</th>\n",
              "      <th>Attrition_Yes</th>\n",
              "      <th>BusinessTravel_Non-Travel</th>\n",
              "      <th>BusinessTravel_Travel_Frequently</th>\n",
              "      <th>BusinessTravel_Travel_Rarely</th>\n",
              "      <th>Department_Human Resources</th>\n",
              "      <th>Department_Research &amp; Development</th>\n",
              "      <th>Department_Sales</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>JobRole_Healthcare Representative</th>\n",
              "      <th>JobRole_Human Resources</th>\n",
              "      <th>JobRole_Laboratory Technician</th>\n",
              "      <th>JobRole_Manager</th>\n",
              "      <th>JobRole_Manufacturing Director</th>\n",
              "      <th>JobRole_Research Director</th>\n",
              "      <th>JobRole_Research Scientist</th>\n",
              "      <th>JobRole_Sales Executive</th>\n",
              "      <th>JobRole_Sales Representative</th>\n",
              "      <th>MaritalStatus_Divorced</th>\n",
              "      <th>MaritalStatus_Married</th>\n",
              "      <th>MaritalStatus_Single</th>\n",
              "      <th>Over18_Y</th>\n",
              "      <th>OverTime_No</th>\n",
              "      <th>OverTime_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>1102</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>279</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1373</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>1392</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>591</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c3b8f2-3a18-43af-9af9-ec403c7731fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45c3b8f2-3a18-43af-9af9-ec403c7731fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45c3b8f2-3a18-43af-9af9-ec403c7731fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Age  DailyRate  DistanceFromHome  ...  Over18_Y  OverTime_No  OverTime_Yes\n",
              "0   41       1102                 1  ...       1.0          0.0           1.0\n",
              "1   49        279                 8  ...       1.0          1.0           0.0\n",
              "2   37       1373                 2  ...       1.0          0.0           1.0\n",
              "3   33       1392                 3  ...       1.0          0.0           1.0\n",
              "4   27        591                 2  ...       1.0          1.0           0.0\n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split training and test data\n",
        "\n",
        "### we use the Attrition_Yes column as the y or target feature and the model input features will be all the columns except Attrition_Yes and Attrition_No"
      ],
      "metadata": {
        "id": "4Xqh1CqnC6Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = attrition_df[\"Attrition_Yes\"].values\n",
        "X = attrition_df.drop([\"Attrition_Yes\",\"Attrition_No\"],1).values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8FCOpkUDa9u",
        "outputId": "ab9af06b-6f7c-4e1d-aa86-505112c168a3"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "gyjWS2JfDixs"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hidden layers, neurons, output layers\n",
        "\n",
        "### input layer: we must add the number of input features equal to the number of variables in our feature DataFrame\n",
        "\n",
        "### hidden layers: our deep learning model structure will be slightly different-we will add two hidden layers with only a few neurons in each layer. To create the second hidden layer, we will add another Keras Dense class while defining our model, all of our hidden layers will use ReLU to identify non linear characteristics from the input values\n",
        "\n",
        "### output layer: we will use the same parameters from our basic neural network including the sigmoid activation function. The sigmoid will help us predict the probability that an employee is at risk for attrition."
      ],
      "metadata": {
        "id": "j-FL5-9qIWdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train[0])\n",
        "# number_input_features = 55\n",
        "hidden_nodes_layer1 = 8\n",
        "hidden_nodes_layer2 = 5\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWqXU4_EJXKl",
        "outputId": "26b8797d-7d53-4e5d-e01f-5bc876a32b1c"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 8)                 448       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 499\n",
            "Trainable params: 499\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we can see that the number of weight parameters(weight coefficients) for each layer equals the number of input values times the number of neurons plus a bias term for eacn neuron. \n",
        "\n",
        "### first layer: 55 input values x 8 neurons + 8 bias terms for each neuron = 448 weight parameters\n",
        "\n",
        "### second layer: 8 neurons from first layer = 8 input values for second layer x 5 neurons + 5 bias terms for each neuron = 45 weight parameters"
      ],
      "metadata": {
        "id": "IUluBli0KgAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "wHsUcxfxLdGD"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train,y_train,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R62g3keJPO4I",
        "outputId": "a778a63b-2ce7-4c3a-a48e-17420215a5ba"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 1s 2ms/step - loss: 1321.2515 - accuracy: 0.1906\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 100.0244 - accuracy: 0.6751\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 36.9526 - accuracy: 0.8285\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 11.1282 - accuracy: 0.8285\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.7629 - accuracy: 0.8285\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8636 - accuracy: 0.8276\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.8276\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.8276\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.8276\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.8276\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.8276\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.8276\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.8276\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.8276\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.8276\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.8276\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.8276\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.8276\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.8276\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.8276\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.8276\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.8276\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.8276\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.8276\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.8276\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.8276\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8276\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.8276\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8276\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8276\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8276\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8276\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8276\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8276\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8276\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8276\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8276\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8276\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8276\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8276\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8276\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8276\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8276\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8276\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8276\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8276\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8276\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8276\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8276\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8276\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8276\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8276\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8276\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8276\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8276\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8276\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8276\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8276\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8276\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8276\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8276\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.8276\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8276\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8276\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8276\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.8276\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8276\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8276\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.8276\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.8276\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8276\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8276\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8276\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8276\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8276\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8276\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8276\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.8276\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8276\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8276\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8276\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8276\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8276\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8276\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8276\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8276\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8276\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8276\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8276\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8276\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8276\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8276\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8276\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8276\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8276\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8276\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8276\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8276\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8276\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfK3GcCiPnvk",
        "outputId": "8a626e11-71d8-4975-88af-789b844a156e"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 - 0s - loss: 0.3927 - accuracy: 0.8723 - 152ms/epoch - 13ms/step\n",
            "Loss: 0.39268597960472107, Accuracy: 0.8722826242446899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## looking at our deep learning model's performance metrics, the model was able to correctly identify employees who are at risk of attrition approximately 87% of the time. considering that our input data included more than 30 different variables with more than 1400 data points, the deep learning model was able to produce a fairly reliable classifier"
      ],
      "metadata": {
        "id": "gb9ITkTLPuZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression VS Basic Neural Network**"
      ],
      "metadata": {
        "id": "4780V7MXRMkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression**:\n",
        "### 1. classification algorithm that can analyze continuous and categorical variables.\n",
        "### 2. using combination of input variables, logistic regression predicts the probability of the input data belonging to one of two groups. if the probability is baove a predetermined cutoff, the sample is assigned to the first group, otherwised it is assigned to the second. \n",
        "### EX: using an applicant's personal information, LR could be used by a bank to determine if a persone does or does not qualify for a credit card\n",
        "\n",
        "### at the hear of the logistic regression model is the sigmoid curve which is produce the probability (between 0 and 1) of the input data belonging to the first group.  sigmoid- S shape curve between 0 and 1. "
      ],
      "metadata": {
        "id": "ltLeH1tdRTY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression model VS Basic Neural Network** \n",
        "\n",
        "### we will use same training/testing dataset"
      ],
      "metadata": {
        "id": "VVuzEphESgWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import our input dataset\n",
        "diabetes_df = pd.read_csv('diabetes.csv')\n",
        "diabetes_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "FPohP0SDSvnZ",
        "outputId": "f9c7162a-7ba2-4c2a-dcc3-9578e4c80859"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-edb6b41d-5824-4adc-9d8c-2b0d82346ebb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edb6b41d-5824-4adc-9d8c-2b0d82346ebb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-edb6b41d-5824-4adc-9d8c-2b0d82346ebb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-edb6b41d-5824-4adc-9d8c-2b0d82346ebb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove diabetes outcome target from features data\n",
        "y = diabetes_df.Outcome\n",
        "X = diabetes_df.drop(columns=\"Outcome\")\n",
        "\n",
        "# Split training/test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "hSNNqIl2S4dB"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess numerical data for neural network\n",
        "\n",
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "mqU6eo-tS7_C"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the logistic regression model\n",
        "log_classifier = LogisticRegression(solver=\"lbfgs\",max_iter=200)\n",
        "# lbfgs which is an algorithm for learning and optimization. the particular solver is not very important in this example but note that a number of optimizer exist\n",
        "# max_iter will be set to 200 iterations which will give the model sufficient oppertunity to converge weights\n",
        "\n",
        "# Train the model\n",
        "log_classifier.fit(X_train,y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = log_classifier.predict(X_test)\n",
        "print(f\" Logistic regression model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEaOtMJYTB0_",
        "outputId": "cfa1eb19-bf3c-49dd-9218-d39f9f5c16b5"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Logistic regression model accuracy: 0.729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Neural Network"
      ],
      "metadata": {
        "id": "0UVMohmTTi0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the basic neural network model\n",
        "nn_model = tf.keras.models.Sequential()\n",
        "nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\", input_dim=8))\n",
        "# 16 neurons\n",
        "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHer9TpMTlyo",
        "outputId": "bd4dd03b-0b33-4b5d-ae67-25e5eedd95f0"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7845 - accuracy: 0.3628\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.4340\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5451\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6372\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7049\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7031\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.7222\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7326\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.7465\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7483\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7569\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7743\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7795\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7830\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7865\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7865\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7847\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7865\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7865\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7865\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7899\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7951\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7969\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8003\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.8003\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8003\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8003\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8021\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7986\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7986\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8003\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7986\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7986\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7986\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7986\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7986\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7986\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7986\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8003\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8003\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7969\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7986\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7986\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7986\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7986\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7986\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7951\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7951\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7986\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8003\n",
            "6/6 - 0s - loss: 0.4874 - accuracy: 0.7188 - 130ms/epoch - 22ms/step\n",
            "Loss: 0.48741865158081055, Accuracy: 0.71875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Both results are similar that they are over 70%\n",
        "\n",
        "### if you are trying to classifier with limited data points(fewer than a thousand data points) or if your dataset has only a few features, neural network may be overcomplicated\n",
        "### logistic regression models are easier to dissect and interpret than neural network which tends to put more traditional data scientists and non-data experts at ease\n",
        "\n",
        "## datasets with thousands of data points or dataset with complex features may overwhelm the logistic regression model while a deep learning model can evaluate every interaction within and across meurons\n",
        "\n",
        "## therefore, the decision between using a logistic regression model and basic neural network model is nuanced and in most cases, a matter of preference for the data scientists"
      ],
      "metadata": {
        "id": "qV4lMclhT5Ke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Support Vector Machine VS Deep Learning Model**"
      ],
      "metadata": {
        "id": "LA9KxL_9VloR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM are supervised learning model that analyze data used for regresssion and classification\n",
        "\n",
        "## If we only compare binary classification problems, SVMs have an advantage over neural network and deep learning models:\n",
        "### 1. Neural Network and deep learning models will often converge on a local minimum. In other words, these models will often focus on a specific trend in the data and could miss the 'bigger picture'\n",
        "### 2. SVMs are less prone to overfitting because they are trying to maximum the distance rather than encompass all data within a boundary\n",
        "\n",
        "\n",
        "## Limitation: SVMs are limited in their potential and can still miss critical features and high-dimensionality relationships that a welltrained deep learning model could find. "
      ],
      "metadata": {
        "id": "ZRcRfFQlVrKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM vs Deel Learning Model\n",
        "\n",
        "### we use same training/testing data"
      ],
      "metadata": {
        "id": "MB03EVi0W2kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import our input dataset\n",
        "tele_df = pd.read_csv('bank_telemarketing.csv')\n",
        "tele_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "1y0gzyVMW9ML",
        "outputId": "50904358-b761-466c-89a8-add0dc4548de"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-657dcc5e-6318-4fa4-a7ab-ab789642de61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Job</th>\n",
              "      <th>Marital_Status</th>\n",
              "      <th>Education</th>\n",
              "      <th>Default_Credit</th>\n",
              "      <th>Housing_Loan</th>\n",
              "      <th>Personal_Loan</th>\n",
              "      <th>Subscribed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>other</td>\n",
              "      <td>married</td>\n",
              "      <td>Primary_Education</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>Secondary_Education</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>admin</td>\n",
              "      <td>married</td>\n",
              "      <td>Primary_Education</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>Secondary_Education</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>admin</td>\n",
              "      <td>married</td>\n",
              "      <td>Professional_Education</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-657dcc5e-6318-4fa4-a7ab-ab789642de61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-657dcc5e-6318-4fa4-a7ab-ab789642de61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-657dcc5e-6318-4fa4-a7ab-ab789642de61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Age       Job Marital_Status  ... Housing_Loan Personal_Loan Subscribed\n",
              "0   56     other        married  ...           no            no         no\n",
              "1   37  services        married  ...          yes            no         no\n",
              "2   40     admin        married  ...           no            no         no\n",
              "3   56  services        married  ...           no           yes         no\n",
              "4   59     admin        married  ...           no            no         no\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate our categorical variable list\n",
        "tele_cat = tele_df.dtypes[tele_df.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "\n",
        "# Check the number of unique values in each column\n",
        "tele_df[tele_cat].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn7K-7VRXMUF",
        "outputId": "e73908f0-573f-4482-a78b-e135b26e7c11"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Job               9\n",
              "Marital_Status    3\n",
              "Education         4\n",
              "Default_Credit    2\n",
              "Housing_Loan      2\n",
              "Personal_Loan     2\n",
              "Subscribed        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(tele_df[tele_cat]))\n",
        "\n",
        "# Add the encoded variable names to the dataframe\n",
        "encode_df.columns = enc.get_feature_names(tele_cat)\n",
        "encode_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "WwzW5sseXQUm",
        "outputId": "9ed06322-ac85-4ed2-dd95-416ddee0a2d4"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a59a6a00-2936-43cf-88d1-882fd260680b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_admin</th>\n",
              "      <th>Job_blue-collar</th>\n",
              "      <th>Job_entrepreneur</th>\n",
              "      <th>Job_management</th>\n",
              "      <th>Job_other</th>\n",
              "      <th>Job_retired</th>\n",
              "      <th>Job_self-employed</th>\n",
              "      <th>Job_services</th>\n",
              "      <th>Job_technician</th>\n",
              "      <th>Marital_Status_divorced</th>\n",
              "      <th>Marital_Status_married</th>\n",
              "      <th>Marital_Status_single</th>\n",
              "      <th>Education_Primary_Education</th>\n",
              "      <th>Education_Professional_Education</th>\n",
              "      <th>Education_Secondary_Education</th>\n",
              "      <th>Education_Tertiary_Education</th>\n",
              "      <th>Default_Credit_no</th>\n",
              "      <th>Default_Credit_yes</th>\n",
              "      <th>Housing_Loan_no</th>\n",
              "      <th>Housing_Loan_yes</th>\n",
              "      <th>Personal_Loan_no</th>\n",
              "      <th>Personal_Loan_yes</th>\n",
              "      <th>Subscribed_no</th>\n",
              "      <th>Subscribed_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a59a6a00-2936-43cf-88d1-882fd260680b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a59a6a00-2936-43cf-88d1-882fd260680b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a59a6a00-2936-43cf-88d1-882fd260680b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Job_admin  Job_blue-collar  ...  Subscribed_no  Subscribed_yes\n",
              "0        0.0              0.0  ...            1.0             0.0\n",
              "1        0.0              0.0  ...            1.0             0.0\n",
              "2        1.0              0.0  ...            1.0             0.0\n",
              "3        0.0              0.0  ...            1.0             0.0\n",
              "4        1.0              0.0  ...            1.0             0.0\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "tele_df = tele_df.merge(encode_df,left_index=True, right_index=True)\n",
        "tele_df = tele_df.drop(tele_cat,1)\n",
        "tele_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "f1DR9u92XU7Q",
        "outputId": "46395ef9-91e7-4cb6-dddd-c92638a83117"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d5063d31-fb13-424e-924c-02c52aa6adc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Job_admin</th>\n",
              "      <th>Job_blue-collar</th>\n",
              "      <th>Job_entrepreneur</th>\n",
              "      <th>Job_management</th>\n",
              "      <th>Job_other</th>\n",
              "      <th>Job_retired</th>\n",
              "      <th>Job_self-employed</th>\n",
              "      <th>Job_services</th>\n",
              "      <th>Job_technician</th>\n",
              "      <th>Marital_Status_divorced</th>\n",
              "      <th>Marital_Status_married</th>\n",
              "      <th>Marital_Status_single</th>\n",
              "      <th>Education_Primary_Education</th>\n",
              "      <th>Education_Professional_Education</th>\n",
              "      <th>Education_Secondary_Education</th>\n",
              "      <th>Education_Tertiary_Education</th>\n",
              "      <th>Default_Credit_no</th>\n",
              "      <th>Default_Credit_yes</th>\n",
              "      <th>Housing_Loan_no</th>\n",
              "      <th>Housing_Loan_yes</th>\n",
              "      <th>Personal_Loan_no</th>\n",
              "      <th>Personal_Loan_yes</th>\n",
              "      <th>Subscribed_no</th>\n",
              "      <th>Subscribed_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5063d31-fb13-424e-924c-02c52aa6adc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5063d31-fb13-424e-924c-02c52aa6adc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5063d31-fb13-424e-924c-02c52aa6adc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Age  Job_admin  ...  Subscribed_no  Subscribed_yes\n",
              "0   56        0.0  ...            1.0             0.0\n",
              "1   37        0.0  ...            1.0             0.0\n",
              "2   40        1.0  ...            1.0             0.0\n",
              "3   56        0.0  ...            1.0             0.0\n",
              "4   59        1.0  ...            1.0             0.0\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove loan status target from features data\n",
        "y = tele_df.Subscribed_yes.values\n",
        "X = tele_df.drop(columns=[\"Subscribed_no\",\"Subscribed_yes\"]).values\n",
        "\n",
        "# Split training/test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "aE-0LC98Xag0"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM Model**"
      ],
      "metadata": {
        "id": "bMewTXMYXcjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the SVM model\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Train the model\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = svm.predict(X_test_scaled)\n",
        "print(f\" SVM model accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3EoXODdXfEr",
        "outputId": "d0605aba-d1be-4880-cad0-d444a5e4e013"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " SVM model accuracy: 0.873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Learning Model**"
      ],
      "metadata": {
        "id": "lCLMboW9X2iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 10\n",
        "hidden_nodes_layer2 = 5\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "UqPdFpIPX5MV"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model \n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) \n",
        "# Evaluate the model using the test data \n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQFJlc8YX9nG",
        "outputId": "f2bfb844-ad7c-4f42-ae6a-562a94b8c96d"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "715/715 [==============================] - 3s 3ms/step - loss: 0.4275 - accuracy: 0.8554\n",
            "Epoch 2/50\n",
            "715/715 [==============================] - 2s 2ms/step - loss: 0.3724 - accuracy: 0.8735\n",
            "Epoch 3/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3701 - accuracy: 0.8734\n",
            "Epoch 4/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8736\n",
            "Epoch 5/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8735\n",
            "Epoch 6/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8733\n",
            "Epoch 7/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3667 - accuracy: 0.8733\n",
            "Epoch 8/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3664 - accuracy: 0.8731\n",
            "Epoch 9/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8733\n",
            "Epoch 10/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8736\n",
            "Epoch 11/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8733\n",
            "Epoch 12/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3651 - accuracy: 0.8733\n",
            "Epoch 13/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3649 - accuracy: 0.8739\n",
            "Epoch 14/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8742\n",
            "Epoch 15/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8739\n",
            "Epoch 16/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8733\n",
            "Epoch 17/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8736\n",
            "Epoch 18/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3637 - accuracy: 0.8734\n",
            "Epoch 19/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8736\n",
            "Epoch 20/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8736\n",
            "Epoch 21/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8741\n",
            "Epoch 22/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8733\n",
            "Epoch 23/50\n",
            "715/715 [==============================] - 3s 4ms/step - loss: 0.3631 - accuracy: 0.8736\n",
            "Epoch 24/50\n",
            "715/715 [==============================] - 2s 3ms/step - loss: 0.3630 - accuracy: 0.8737\n",
            "Epoch 25/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8736\n",
            "Epoch 26/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8736\n",
            "Epoch 27/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8735\n",
            "Epoch 28/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8736\n",
            "Epoch 29/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8734\n",
            "Epoch 30/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8736\n",
            "Epoch 31/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8739\n",
            "Epoch 32/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8737\n",
            "Epoch 33/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8738\n",
            "Epoch 34/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8740\n",
            "Epoch 35/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8734\n",
            "Epoch 36/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8735\n",
            "Epoch 37/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8729\n",
            "Epoch 38/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8736\n",
            "Epoch 39/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8736\n",
            "Epoch 40/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8730\n",
            "Epoch 41/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8735\n",
            "Epoch 42/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8733\n",
            "Epoch 43/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8737\n",
            "Epoch 44/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8735\n",
            "Epoch 45/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8733\n",
            "Epoch 46/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8736\n",
            "Epoch 47/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8737\n",
            "Epoch 48/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3616 - accuracy: 0.8736\n",
            "Epoch 49/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3616 - accuracy: 0.8737\n",
            "Epoch 50/50\n",
            "715/715 [==============================] - 1s 2ms/step - loss: 0.3616 - accuracy: 0.8733\n",
            "239/239 - 0s - loss: 0.3682 - accuracy: 0.8731 - 383ms/epoch - 2ms/step\n",
            "Loss: 0.36821427941322327, Accuracy: 0.8730971217155457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## both models perform with accuracy around 87% and take similar amounts of time to test. Since the amount of code required to build and train the SVM is notably less than the deep learning model. As result, many data scientists will prefer to use SVMs by default, then turn to deep learning models as needed. "
      ],
      "metadata": {
        "id": "fYoAZ_Dha5aB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest VS Deep Learning Model**"
      ],
      "metadata": {
        "id": "Vt1ZSGcDcNVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest models use a number of weak learner algorithm (decision trees) and combine their output to make a final classification (or regression) decision. \n",
        "## Random Forest is a supervised ensemble learning model that combines decision trees to analyze input data\n",
        "\n",
        "### RF only handal tabular data, so data such as images or natural language data cannot be used in a RF without heavy modifications to the data.\n",
        "\n",
        "### RF are dependent on each weak learner being trained on a subset of the input data. \n",
        "\n",
        "## Deep Learning model might be able to identify variablility in a dataset that RF model could miss"
      ],
      "metadata": {
        "id": "o-8YpFmAcR0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest VS Deep Learning Model\n",
        "\n",
        "### we use same training/testing data"
      ],
      "metadata": {
        "id": "y6nbLU7rdkQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import our input dataset\n",
        "loans_df = pd.read_csv('loan_status.csv')\n",
        "loans_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "nHN_Fz9hdqbc",
        "outputId": "48ac9229-2352-4c7e-eb41-b92a10a18018"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d726fe51-58c8-409d-baea-38822c56544f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_Status</th>\n",
              "      <th>Current_Loan_Amount</th>\n",
              "      <th>Term</th>\n",
              "      <th>Credit_Score</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Years_in_current_job</th>\n",
              "      <th>Home_Ownership</th>\n",
              "      <th>Purpose</th>\n",
              "      <th>Monthly_Debt</th>\n",
              "      <th>Years_of_Credit_History</th>\n",
              "      <th>Months_since_last_delinquent</th>\n",
              "      <th>Number_of_Open_Accounts</th>\n",
              "      <th>Number_of_Credit_Problems</th>\n",
              "      <th>Current_Credit_Balance</th>\n",
              "      <th>Maximum_Open_Credit</th>\n",
              "      <th>Bankruptcies</th>\n",
              "      <th>Tax_Liens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fully_Paid</td>\n",
              "      <td>99999999</td>\n",
              "      <td>Short_Term</td>\n",
              "      <td>741.0</td>\n",
              "      <td>2231892.0</td>\n",
              "      <td>8_years</td>\n",
              "      <td>Own_Home</td>\n",
              "      <td>Debt_Consolidation</td>\n",
              "      <td>29200.53</td>\n",
              "      <td>14.9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>297996</td>\n",
              "      <td>750090.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fully_Paid</td>\n",
              "      <td>217646</td>\n",
              "      <td>Short_Term</td>\n",
              "      <td>730.0</td>\n",
              "      <td>1184194.0</td>\n",
              "      <td>&lt;_1_year</td>\n",
              "      <td>Home_Mortgage</td>\n",
              "      <td>Debt_Consolidation</td>\n",
              "      <td>10855.08</td>\n",
              "      <td>19.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>122170</td>\n",
              "      <td>272052.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fully_Paid</td>\n",
              "      <td>548746</td>\n",
              "      <td>Short_Term</td>\n",
              "      <td>678.0</td>\n",
              "      <td>2559110.0</td>\n",
              "      <td>2_years</td>\n",
              "      <td>Rent</td>\n",
              "      <td>Debt_Consolidation</td>\n",
              "      <td>18660.28</td>\n",
              "      <td>22.6</td>\n",
              "      <td>33.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>437171</td>\n",
              "      <td>555038.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fully_Paid</td>\n",
              "      <td>99999999</td>\n",
              "      <td>Short_Term</td>\n",
              "      <td>728.0</td>\n",
              "      <td>714628.0</td>\n",
              "      <td>3_years</td>\n",
              "      <td>Rent</td>\n",
              "      <td>Debt_Consolidation</td>\n",
              "      <td>11851.06</td>\n",
              "      <td>16.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>203965</td>\n",
              "      <td>289784.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fully_Paid</td>\n",
              "      <td>99999999</td>\n",
              "      <td>Short_Term</td>\n",
              "      <td>740.0</td>\n",
              "      <td>776188.0</td>\n",
              "      <td>&lt;_1_year</td>\n",
              "      <td>Own_Home</td>\n",
              "      <td>Debt_Consolidation</td>\n",
              "      <td>11578.22</td>\n",
              "      <td>8.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>134083</td>\n",
              "      <td>220220.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d726fe51-58c8-409d-baea-38822c56544f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d726fe51-58c8-409d-baea-38822c56544f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d726fe51-58c8-409d-baea-38822c56544f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Loan_Status  Current_Loan_Amount  ... Bankruptcies  Tax_Liens\n",
              "0  Fully_Paid             99999999  ...          0.0        0.0\n",
              "1  Fully_Paid               217646  ...          1.0        0.0\n",
              "2  Fully_Paid               548746  ...          0.0        0.0\n",
              "3  Fully_Paid             99999999  ...          0.0        0.0\n",
              "4  Fully_Paid             99999999  ...          0.0        0.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate our categorical variable list\n",
        "loans_cat = loans_df.dtypes[loans_df.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "# Check the number of unique values in each column\n",
        "loans_df[loans_cat].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gPK-RSfdvrv",
        "outputId": "9b96c4e4-e5f2-4cf4-f2be-7da9b5415d03"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Loan_Status              2\n",
              "Term                     2\n",
              "Years_in_current_job    11\n",
              "Home_Ownership           4\n",
              "Purpose                  7\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### since the Years_in_current_job column has 11 unique values. so we should check the number of data points for each unique value to find out if any categorical variables can be bucketed together"
      ],
      "metadata": {
        "id": "izcCIkQjd1wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the unique value counts to see if binning is required\n",
        "loans_df.Years_in_current_job.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPkM8AA3eEr6",
        "outputId": "08c93b31-e87e-402d-f748-6fa1a17c4172"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10+_years    13149\n",
              "2_years       3225\n",
              "3_years       2997\n",
              "<_1_year      2699\n",
              "5_years       2487\n",
              "4_years       2286\n",
              "1_year        2247\n",
              "6_years       2109\n",
              "7_years       2082\n",
              "8_years       1675\n",
              "9_years       1467\n",
              "Name: Years_in_current_job, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### all of the categorical values have a supstantial number of data points. in this case, we have reason to leave the years_in_current_job column alone because we dont want to bucket common values together and cause confusion in the model "
      ],
      "metadata": {
        "id": "xzbRDxySeM7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a OneHotEncoder instance\n",
        "enc = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the OneHotEncoder using the categorical variable list\n",
        "encode_df = pd.DataFrame(enc.fit_transform(loans_df[loans_cat]))\n",
        "\n",
        "# Add the encoded variable names to the DataFrame\n",
        "encode_df.columns = enc.get_feature_names(loans_cat)\n",
        "encode_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "k6NjkacLebop",
        "outputId": "0d95ce9b-409f-40ba-c8fe-2ab414670f3a"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-53b20c27-c731-417b-a61b-2f30b45d2cb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loan_Status_Fully_Paid</th>\n",
              "      <th>Loan_Status_Not_Paid</th>\n",
              "      <th>Term_Long_Term</th>\n",
              "      <th>Term_Short_Term</th>\n",
              "      <th>Years_in_current_job_10+_years</th>\n",
              "      <th>Years_in_current_job_1_year</th>\n",
              "      <th>Years_in_current_job_2_years</th>\n",
              "      <th>Years_in_current_job_3_years</th>\n",
              "      <th>Years_in_current_job_4_years</th>\n",
              "      <th>Years_in_current_job_5_years</th>\n",
              "      <th>Years_in_current_job_6_years</th>\n",
              "      <th>Years_in_current_job_7_years</th>\n",
              "      <th>Years_in_current_job_8_years</th>\n",
              "      <th>Years_in_current_job_9_years</th>\n",
              "      <th>Years_in_current_job_&lt;_1_year</th>\n",
              "      <th>Home_Ownership_HaveMortgage</th>\n",
              "      <th>Home_Ownership_Home_Mortgage</th>\n",
              "      <th>Home_Ownership_Own_Home</th>\n",
              "      <th>Home_Ownership_Rent</th>\n",
              "      <th>Purpose_Business_Loan</th>\n",
              "      <th>Purpose_Buy_House</th>\n",
              "      <th>Purpose_Buy_a_Car</th>\n",
              "      <th>Purpose_Debt_Consolidation</th>\n",
              "      <th>Purpose_Home_Improvements</th>\n",
              "      <th>Purpose_Medical_Bills</th>\n",
              "      <th>Purpose_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53b20c27-c731-417b-a61b-2f30b45d2cb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53b20c27-c731-417b-a61b-2f30b45d2cb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53b20c27-c731-417b-a61b-2f30b45d2cb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Loan_Status_Fully_Paid  ...  Purpose_Other\n",
              "0                     1.0  ...            0.0\n",
              "1                     1.0  ...            0.0\n",
              "2                     1.0  ...            0.0\n",
              "3                     1.0  ...            0.0\n",
              "4                     1.0  ...            0.0\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge one-hot encoded features and drop the originals\n",
        "loans_df = loans_df.merge(encode_df,left_index=True, right_index=True)\n",
        "loans_df = loans_df.drop(loans_cat,1)\n",
        "loans_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "Izw0-QwWegfF",
        "outputId": "f5897965-7ab1-4191-abdb-100c1263f250"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df2123a3-83df-47f1-aad1-634511376d72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Current_Loan_Amount</th>\n",
              "      <th>Credit_Score</th>\n",
              "      <th>Annual_Income</th>\n",
              "      <th>Monthly_Debt</th>\n",
              "      <th>Years_of_Credit_History</th>\n",
              "      <th>Months_since_last_delinquent</th>\n",
              "      <th>Number_of_Open_Accounts</th>\n",
              "      <th>Number_of_Credit_Problems</th>\n",
              "      <th>Current_Credit_Balance</th>\n",
              "      <th>Maximum_Open_Credit</th>\n",
              "      <th>Bankruptcies</th>\n",
              "      <th>Tax_Liens</th>\n",
              "      <th>Loan_Status_Fully_Paid</th>\n",
              "      <th>Loan_Status_Not_Paid</th>\n",
              "      <th>Term_Long_Term</th>\n",
              "      <th>Term_Short_Term</th>\n",
              "      <th>Years_in_current_job_10+_years</th>\n",
              "      <th>Years_in_current_job_1_year</th>\n",
              "      <th>Years_in_current_job_2_years</th>\n",
              "      <th>Years_in_current_job_3_years</th>\n",
              "      <th>Years_in_current_job_4_years</th>\n",
              "      <th>Years_in_current_job_5_years</th>\n",
              "      <th>Years_in_current_job_6_years</th>\n",
              "      <th>Years_in_current_job_7_years</th>\n",
              "      <th>Years_in_current_job_8_years</th>\n",
              "      <th>Years_in_current_job_9_years</th>\n",
              "      <th>Years_in_current_job_&lt;_1_year</th>\n",
              "      <th>Home_Ownership_HaveMortgage</th>\n",
              "      <th>Home_Ownership_Home_Mortgage</th>\n",
              "      <th>Home_Ownership_Own_Home</th>\n",
              "      <th>Home_Ownership_Rent</th>\n",
              "      <th>Purpose_Business_Loan</th>\n",
              "      <th>Purpose_Buy_House</th>\n",
              "      <th>Purpose_Buy_a_Car</th>\n",
              "      <th>Purpose_Debt_Consolidation</th>\n",
              "      <th>Purpose_Home_Improvements</th>\n",
              "      <th>Purpose_Medical_Bills</th>\n",
              "      <th>Purpose_Other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99999999</td>\n",
              "      <td>741.0</td>\n",
              "      <td>2231892.0</td>\n",
              "      <td>29200.53</td>\n",
              "      <td>14.9</td>\n",
              "      <td>29.0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>297996</td>\n",
              "      <td>750090.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>217646</td>\n",
              "      <td>730.0</td>\n",
              "      <td>1184194.0</td>\n",
              "      <td>10855.08</td>\n",
              "      <td>19.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>122170</td>\n",
              "      <td>272052.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>548746</td>\n",
              "      <td>678.0</td>\n",
              "      <td>2559110.0</td>\n",
              "      <td>18660.28</td>\n",
              "      <td>22.6</td>\n",
              "      <td>33.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>437171</td>\n",
              "      <td>555038.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99999999</td>\n",
              "      <td>728.0</td>\n",
              "      <td>714628.0</td>\n",
              "      <td>11851.06</td>\n",
              "      <td>16.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>203965</td>\n",
              "      <td>289784.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>99999999</td>\n",
              "      <td>740.0</td>\n",
              "      <td>776188.0</td>\n",
              "      <td>11578.22</td>\n",
              "      <td>8.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>134083</td>\n",
              "      <td>220220.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df2123a3-83df-47f1-aad1-634511376d72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df2123a3-83df-47f1-aad1-634511376d72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df2123a3-83df-47f1-aad1-634511376d72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Current_Loan_Amount  Credit_Score  ...  Purpose_Medical_Bills  Purpose_Other\n",
              "0             99999999         741.0  ...                    0.0            0.0\n",
              "1               217646         730.0  ...                    0.0            0.0\n",
              "2               548746         678.0  ...                    0.0            0.0\n",
              "3             99999999         728.0  ...                    0.0            0.0\n",
              "4             99999999         740.0  ...                    0.0            0.0\n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove loan status target from features data\n",
        "y = loans_df.Loan_Status_Fully_Paid\n",
        "X = loans_df.drop(columns=[\"Loan_Status_Fully_Paid\",\"Loan_Status_Not_Paid\"])\n",
        "\n",
        "# Split training/test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "tFTWDCUbeksY"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "r8puVJvle0eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random forest classifier.\n",
        "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
        "\n",
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_s_gq4fenew",
        "outputId": "55236f99-c2ef-4de3-ad3f-c5d3a01e2708"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random forest predictive accuracy: 0.849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Deep Learning Model**"
      ],
      "metadata": {
        "id": "TH8aCne9e7p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 24\n",
        "hidden_nodes_layer2 = 12\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Output layer\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the Sequential model together and customize metrics\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QMpsp-Ae-i1",
        "outputId": "f28337f2-56da-4756-f27b-7458c1896c58"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "854/854 [==============================] - 3s 3ms/step - loss: 0.4182 - accuracy: 0.8401\n",
            "Epoch 2/50\n",
            "854/854 [==============================] - 2s 2ms/step - loss: 0.3870 - accuracy: 0.8487\n",
            "Epoch 3/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3823 - accuracy: 0.8492\n",
            "Epoch 4/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3800 - accuracy: 0.8494\n",
            "Epoch 5/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3782 - accuracy: 0.8491\n",
            "Epoch 6/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3775 - accuracy: 0.8493\n",
            "Epoch 7/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3760 - accuracy: 0.8493\n",
            "Epoch 8/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3752 - accuracy: 0.8498\n",
            "Epoch 9/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3751 - accuracy: 0.8492\n",
            "Epoch 10/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3745 - accuracy: 0.8494\n",
            "Epoch 11/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3737 - accuracy: 0.8499\n",
            "Epoch 12/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3734 - accuracy: 0.8498\n",
            "Epoch 13/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8501\n",
            "Epoch 14/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3729 - accuracy: 0.8499\n",
            "Epoch 15/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8501\n",
            "Epoch 16/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3717 - accuracy: 0.8500\n",
            "Epoch 17/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3715 - accuracy: 0.8500\n",
            "Epoch 18/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.8500\n",
            "Epoch 19/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8503\n",
            "Epoch 20/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3705 - accuracy: 0.8501\n",
            "Epoch 21/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3702 - accuracy: 0.8506\n",
            "Epoch 22/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3696 - accuracy: 0.8507\n",
            "Epoch 23/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8502\n",
            "Epoch 24/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8506\n",
            "Epoch 25/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3689 - accuracy: 0.8504\n",
            "Epoch 26/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8509\n",
            "Epoch 27/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8506\n",
            "Epoch 28/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8503\n",
            "Epoch 29/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8511\n",
            "Epoch 30/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3671 - accuracy: 0.8508\n",
            "Epoch 31/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3667 - accuracy: 0.8509\n",
            "Epoch 32/50\n",
            "854/854 [==============================] - 2s 2ms/step - loss: 0.3663 - accuracy: 0.8506\n",
            "Epoch 33/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8506\n",
            "Epoch 34/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8508\n",
            "Epoch 35/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8509\n",
            "Epoch 36/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8510\n",
            "Epoch 37/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8510\n",
            "Epoch 38/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8516\n",
            "Epoch 39/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8509\n",
            "Epoch 40/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8509\n",
            "Epoch 41/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8515\n",
            "Epoch 42/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8519\n",
            "Epoch 43/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8513\n",
            "Epoch 44/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8516\n",
            "Epoch 45/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8517\n",
            "Epoch 46/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8514\n",
            "Epoch 47/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8517\n",
            "Epoch 48/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8514\n",
            "Epoch 49/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8523\n",
            "Epoch 50/50\n",
            "854/854 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8522\n",
            "285/285 - 1s - loss: 0.3874 - accuracy: 0.8458 - 900ms/epoch - 3ms/step\n",
            "Loss: 0.3874354362487793, Accuracy: 0.8458159565925598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## their output is very similar that both random forest and deep learning model are able to predict correctly whether or not a loan will be repaid around 85% of the time. \n",
        "## the random forest classifier finishes the test faster than deep learning model and requires less codes. The ultimate decision of wheather to use a random forest versus a neural network comes down to preference. However, if your dataset is tabular, random forest is a great place to start"
      ],
      "metadata": {
        "id": "u8KDSpuBfWQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checkpoints**"
      ],
      "metadata": {
        "id": "0Fx9BofoxcRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## rerun the deep learning model section until the summary() step\n",
        "\n",
        "## then we are ready to compile and train our model using checkpoints\n",
        "\n",
        "## to use checkpoints, we need to define the checkpoint file name and the directory path. \n",
        "\n",
        "# for our purposesm we will label our checkpoints by epoch number and contain them within their own folder."
      ],
      "metadata": {
        "id": "3lMCKTqCxike"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import checkpoint dependencies\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# define the checkpoint path and filenames\n",
        "os.makedirs('checkpoints/', exist_ok=True)\n",
        "checkpoint_path = 'checkpoints/weights.{epoch:02d}.hdf5'"
      ],
      "metadata": {
        "id": "yepWqpfkzPwd"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Once we have defined the file structure and filepath. we need to create a **callback** object for our deep learning model. a callback object is used in Keras module to define as a set of functions that will be applied at specific stages of the training process.\n",
        "\n",
        "## callback functions can create log files, force training to stop, send training status messages or in our case save model checkpoints. "
      ],
      "metadata": {
        "id": "jh6zikh6zpRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Create a callback that saves the model's weights every epoch\n",
        "cp_callback = ModelCheckpoint( \n",
        "    filepath=checkpoint_path, # the check point directory and file structure we defined previously\n",
        "    verbose=1, # we will be notified when a checkpoint is being saved to the directory\n",
        "    save_weights_only=True, # saving the full model each time can fill up a hard drive very quickly; this ensures that the checkpoint files take up minimum space\n",
        "    save_freq='epoch') # checkpoints will be saved every epoch\n",
        "\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORx0Y9PA0VpE",
        "outputId": "b6d3f645-3e10-426d-879c-e86b42006c36"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.6167 - accuracy: 0.6316 \n",
            "Epoch 1: saving model to checkpoints/weights.01.hdf5\n",
            "35/35 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.6343\n",
            "Epoch 2/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.5277 - accuracy: 0.7585\n",
            "Epoch 2: saving model to checkpoints/weights.02.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7623\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4636 - accuracy: 0.8203\n",
            "Epoch 3: saving model to checkpoints/weights.03.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8203\n",
            "Epoch 4/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.4164 - accuracy: 0.8469\n",
            "Epoch 4: saving model to checkpoints/weights.04.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8367\n",
            "Epoch 5/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.3955 - accuracy: 0.8535\n",
            "Epoch 5: saving model to checkpoints/weights.05.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8557\n",
            "Epoch 6/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.3701 - accuracy: 0.8669\n",
            "Epoch 6: saving model to checkpoints/weights.06.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8639\n",
            "Epoch 7/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.3620 - accuracy: 0.8646\n",
            "Epoch 7: saving model to checkpoints/weights.07.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8693\n",
            "Epoch 8/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.3517 - accuracy: 0.8721\n",
            "Epoch 8: saving model to checkpoints/weights.08.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8766\n",
            "Epoch 9/100\n",
            "24/35 [===================>..........] - ETA: 0s - loss: 0.3348 - accuracy: 0.8802\n",
            "Epoch 9: saving model to checkpoints/weights.09.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8802\n",
            "Epoch 10/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.3403 - accuracy: 0.8818\n",
            "Epoch 10: saving model to checkpoints/weights.10.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8848\n",
            "Epoch 11/100\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.3174 - accuracy: 0.8917\n",
            "Epoch 11: saving model to checkpoints/weights.11.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8893\n",
            "Epoch 12/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.3169 - accuracy: 0.8891\n",
            "Epoch 12: saving model to checkpoints/weights.12.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8920\n",
            "Epoch 13/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.3042 - accuracy: 0.8952\n",
            "Epoch 13: saving model to checkpoints/weights.13.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3099 - accuracy: 0.8920\n",
            "Epoch 14/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.3110 - accuracy: 0.8916\n",
            "Epoch 14: saving model to checkpoints/weights.14.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8966\n",
            "Epoch 15/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.2978 - accuracy: 0.9006\n",
            "Epoch 15: saving model to checkpoints/weights.15.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8993\n",
            "Epoch 16/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2930 - accuracy: 0.8962\n",
            "Epoch 16: saving model to checkpoints/weights.16.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2935 - accuracy: 0.8966\n",
            "Epoch 17/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2963 - accuracy: 0.8962\n",
            "Epoch 17: saving model to checkpoints/weights.17.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8993\n",
            "Epoch 18/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2879 - accuracy: 0.8948\n",
            "Epoch 18: saving model to checkpoints/weights.18.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.8975\n",
            "Epoch 19/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2629 - accuracy: 0.9113\n",
            "Epoch 19: saving model to checkpoints/weights.19.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9020\n",
            "Epoch 20/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2789 - accuracy: 0.8982\n",
            "Epoch 20: saving model to checkpoints/weights.20.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8984\n",
            "Epoch 21/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.2781 - accuracy: 0.8981\n",
            "Epoch 21: saving model to checkpoints/weights.21.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.9029\n",
            "Epoch 22/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.2701 - accuracy: 0.9095\n",
            "Epoch 22: saving model to checkpoints/weights.22.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9047\n",
            "Epoch 23/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2698 - accuracy: 0.9031\n",
            "Epoch 23: saving model to checkpoints/weights.23.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2674 - accuracy: 0.9020\n",
            "Epoch 24/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2694 - accuracy: 0.9042\n",
            "Epoch 24: saving model to checkpoints/weights.24.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9047\n",
            "Epoch 25/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2592 - accuracy: 0.9032\n",
            "Epoch 25: saving model to checkpoints/weights.25.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.9038\n",
            "Epoch 26/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.2586 - accuracy: 0.9051\n",
            "Epoch 26: saving model to checkpoints/weights.26.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9038\n",
            "Epoch 27/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2648 - accuracy: 0.9042\n",
            "Epoch 27: saving model to checkpoints/weights.27.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.9056\n",
            "Epoch 28/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.2535 - accuracy: 0.9091\n",
            "Epoch 28: saving model to checkpoints/weights.28.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9083\n",
            "Epoch 29/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.2482 - accuracy: 0.9127\n",
            "Epoch 29: saving model to checkpoints/weights.29.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9111\n",
            "Epoch 30/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2442 - accuracy: 0.9135\n",
            "Epoch 30: saving model to checkpoints/weights.30.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9129\n",
            "Epoch 31/100\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.2503 - accuracy: 0.9163\n",
            "Epoch 31: saving model to checkpoints/weights.31.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9147\n",
            "Epoch 32/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.2426 - accuracy: 0.9150\n",
            "Epoch 32: saving model to checkpoints/weights.32.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9120\n",
            "Epoch 33/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.2412 - accuracy: 0.9111\n",
            "Epoch 33: saving model to checkpoints/weights.33.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.9102\n",
            "Epoch 34/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2378 - accuracy: 0.9177\n",
            "Epoch 34: saving model to checkpoints/weights.34.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.9165\n",
            "Epoch 35/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2399 - accuracy: 0.9143\n",
            "Epoch 35: saving model to checkpoints/weights.35.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.9174\n",
            "Epoch 36/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2235 - accuracy: 0.9260\n",
            "Epoch 36: saving model to checkpoints/weights.36.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9183\n",
            "Epoch 37/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2308 - accuracy: 0.9194\n",
            "Epoch 37: saving model to checkpoints/weights.37.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.9174\n",
            "Epoch 38/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2228 - accuracy: 0.9214\n",
            "Epoch 38: saving model to checkpoints/weights.38.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9192\n",
            "Epoch 39/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2259 - accuracy: 0.9183\n",
            "Epoch 39: saving model to checkpoints/weights.39.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2265 - accuracy: 0.9183\n",
            "Epoch 40/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2337 - accuracy: 0.9163\n",
            "Epoch 40: saving model to checkpoints/weights.40.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.9201\n",
            "Epoch 41/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2175 - accuracy: 0.9204\n",
            "Epoch 41: saving model to checkpoints/weights.41.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9192\n",
            "Epoch 42/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.2132 - accuracy: 0.9250\n",
            "Epoch 42: saving model to checkpoints/weights.42.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.9211\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.9211\n",
            "Epoch 43: saving model to checkpoints/weights.43.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9211\n",
            "Epoch 44/100\n",
            "21/35 [=================>............] - ETA: 0s - loss: 0.2259 - accuracy: 0.9152\n",
            "Epoch 44: saving model to checkpoints/weights.44.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9192\n",
            "Epoch 45/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.2182 - accuracy: 0.9233\n",
            "Epoch 45: saving model to checkpoints/weights.45.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9247\n",
            "Epoch 46/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2068 - accuracy: 0.9274\n",
            "Epoch 46: saving model to checkpoints/weights.46.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9247\n",
            "Epoch 47/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.2086 - accuracy: 0.9238\n",
            "Epoch 47: saving model to checkpoints/weights.47.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9238\n",
            "Epoch 48/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2045 - accuracy: 0.9234\n",
            "Epoch 48: saving model to checkpoints/weights.48.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9220\n",
            "Epoch 49/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.2022 - accuracy: 0.9294\n",
            "Epoch 49: saving model to checkpoints/weights.49.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9265\n",
            "Epoch 50/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.2041 - accuracy: 0.9290\n",
            "Epoch 50: saving model to checkpoints/weights.50.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9274\n",
            "Epoch 51/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.2049 - accuracy: 0.9234\n",
            "Epoch 51: saving model to checkpoints/weights.51.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9265\n",
            "Epoch 52/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.2006 - accuracy: 0.9271\n",
            "Epoch 52: saving model to checkpoints/weights.52.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9283\n",
            "Epoch 53/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.1982 - accuracy: 0.9294\n",
            "Epoch 53: saving model to checkpoints/weights.53.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9292\n",
            "Epoch 54/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.1975 - accuracy: 0.9340\n",
            "Epoch 54: saving model to checkpoints/weights.54.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9328\n",
            "Epoch 55/100\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.1911 - accuracy: 0.9375\n",
            "Epoch 55: saving model to checkpoints/weights.55.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9374\n",
            "Epoch 56/100\n",
            "24/35 [===================>..........] - ETA: 0s - loss: 0.1978 - accuracy: 0.9310\n",
            "Epoch 56: saving model to checkpoints/weights.56.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9310\n",
            "Epoch 57/100\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.1886 - accuracy: 0.9353\n",
            "Epoch 57: saving model to checkpoints/weights.57.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9328\n",
            "Epoch 58/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1938 - accuracy: 0.9344\n",
            "Epoch 58: saving model to checkpoints/weights.58.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9347\n",
            "Epoch 59/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.1781 - accuracy: 0.9398\n",
            "Epoch 59: saving model to checkpoints/weights.59.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9356\n",
            "Epoch 60/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1890 - accuracy: 0.9328\n",
            "Epoch 60: saving model to checkpoints/weights.60.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9338\n",
            "Epoch 61/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1785 - accuracy: 0.9375\n",
            "Epoch 61: saving model to checkpoints/weights.61.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9338\n",
            "Epoch 62/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1866 - accuracy: 0.9365\n",
            "Epoch 62: saving model to checkpoints/weights.62.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9374\n",
            "Epoch 63/100\n",
            "26/35 [=====================>........] - ETA: 0s - loss: 0.1724 - accuracy: 0.9471\n",
            "Epoch 63: saving model to checkpoints/weights.63.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9392\n",
            "Epoch 64/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1779 - accuracy: 0.9396\n",
            "Epoch 64: saving model to checkpoints/weights.64.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9383\n",
            "Epoch 65/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1734 - accuracy: 0.9406\n",
            "Epoch 65: saving model to checkpoints/weights.65.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9401\n",
            "Epoch 66/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.1707 - accuracy: 0.9440\n",
            "Epoch 66: saving model to checkpoints/weights.66.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9401\n",
            "Epoch 67/100\n",
            "16/35 [============>.................] - ETA: 0s - loss: 0.1812 - accuracy: 0.9414\n",
            "Epoch 67: saving model to checkpoints/weights.67.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9401\n",
            "Epoch 68/100\n",
            "26/35 [=====================>........] - ETA: 0s - loss: 0.1767 - accuracy: 0.9327\n",
            "Epoch 68: saving model to checkpoints/weights.68.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.9392\n",
            "Epoch 69/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1760 - accuracy: 0.9453\n",
            "Epoch 69: saving model to checkpoints/weights.69.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1736 - accuracy: 0.9456\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9419\n",
            "Epoch 70: saving model to checkpoints/weights.70.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9419\n",
            "Epoch 71/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1643 - accuracy: 0.9502\n",
            "Epoch 71: saving model to checkpoints/weights.71.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9465\n",
            "Epoch 72/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1704 - accuracy: 0.9443\n",
            "Epoch 72: saving model to checkpoints/weights.72.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9456\n",
            "Epoch 73/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1639 - accuracy: 0.9469\n",
            "Epoch 73: saving model to checkpoints/weights.73.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9456\n",
            "Epoch 74/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1667 - accuracy: 0.9456\n",
            "Epoch 74: saving model to checkpoints/weights.74.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9456\n",
            "Epoch 75/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.1541 - accuracy: 0.9494\n",
            "Epoch 75: saving model to checkpoints/weights.75.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9456\n",
            "Epoch 76/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9467\n",
            "Epoch 76: saving model to checkpoints/weights.76.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9465\n",
            "Epoch 77/100\n",
            "25/35 [====================>.........] - ETA: 0s - loss: 0.1690 - accuracy: 0.9400\n",
            "Epoch 77: saving model to checkpoints/weights.77.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9456\n",
            "Epoch 78/100\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.1541 - accuracy: 0.9498\n",
            "Epoch 78: saving model to checkpoints/weights.78.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1599 - accuracy: 0.9474\n",
            "Epoch 79/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.1664 - accuracy: 0.9429\n",
            "Epoch 79: saving model to checkpoints/weights.79.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9465\n",
            "Epoch 80/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1595 - accuracy: 0.9489\n",
            "Epoch 80: saving model to checkpoints/weights.80.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9483\n",
            "Epoch 81/100\n",
            "28/35 [=======================>......] - ETA: 0s - loss: 0.1558 - accuracy: 0.9453\n",
            "Epoch 81: saving model to checkpoints/weights.81.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9465\n",
            "Epoch 82/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1588 - accuracy: 0.9441\n",
            "Epoch 82: saving model to checkpoints/weights.82.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9465\n",
            "Epoch 83/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1477 - accuracy: 0.9496\n",
            "Epoch 83: saving model to checkpoints/weights.83.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9474\n",
            "Epoch 84/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1495 - accuracy: 0.9490\n",
            "Epoch 84: saving model to checkpoints/weights.84.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9483\n",
            "Epoch 85/100\n",
            "34/35 [============================>.] - ETA: 0s - loss: 0.1538 - accuracy: 0.9504\n",
            "Epoch 85: saving model to checkpoints/weights.85.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9510\n",
            "Epoch 86/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1392 - accuracy: 0.9556\n",
            "Epoch 86: saving model to checkpoints/weights.86.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9501\n",
            "Epoch 87/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1493 - accuracy: 0.9489\n",
            "Epoch 87: saving model to checkpoints/weights.87.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9492\n",
            "Epoch 88/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1502 - accuracy: 0.9463\n",
            "Epoch 88: saving model to checkpoints/weights.88.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9483\n",
            "Epoch 89/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.1474 - accuracy: 0.9450\n",
            "Epoch 89: saving model to checkpoints/weights.89.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9437\n",
            "Epoch 90/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1469 - accuracy: 0.9479\n",
            "Epoch 90: saving model to checkpoints/weights.90.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9492\n",
            "Epoch 91/100\n",
            "31/35 [=========================>....] - ETA: 0s - loss: 0.1392 - accuracy: 0.9496\n",
            "Epoch 91: saving model to checkpoints/weights.91.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9474\n",
            "Epoch 92/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1437 - accuracy: 0.9512\n",
            "Epoch 92: saving model to checkpoints/weights.92.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9501\n",
            "Epoch 93/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1367 - accuracy: 0.9561\n",
            "Epoch 93: saving model to checkpoints/weights.93.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9510\n",
            "Epoch 94/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1457 - accuracy: 0.9448\n",
            "Epoch 94: saving model to checkpoints/weights.94.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1420 - accuracy: 0.9483\n",
            "Epoch 95/100\n",
            "33/35 [===========================>..] - ETA: 0s - loss: 0.1386 - accuracy: 0.9498\n",
            "Epoch 95: saving model to checkpoints/weights.95.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9501\n",
            "Epoch 96/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.1324 - accuracy: 0.9569\n",
            "Epoch 96: saving model to checkpoints/weights.96.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9519\n",
            "Epoch 97/100\n",
            "29/35 [=======================>......] - ETA: 0s - loss: 0.1285 - accuracy: 0.9569\n",
            "Epoch 97: saving model to checkpoints/weights.97.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9519\n",
            "Epoch 98/100\n",
            "30/35 [========================>.....] - ETA: 0s - loss: 0.1342 - accuracy: 0.9490\n",
            "Epoch 98: saving model to checkpoints/weights.98.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9483\n",
            "Epoch 99/100\n",
            "32/35 [==========================>...] - ETA: 0s - loss: 0.1375 - accuracy: 0.9473\n",
            "Epoch 99: saving model to checkpoints/weights.99.hdf5\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9492\n",
            "Epoch 100/100\n",
            "27/35 [======================>.......] - ETA: 0s - loss: 0.1258 - accuracy: 0.9537\n",
            "Epoch 100: saving model to checkpoints/weights.100.hdf5\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9492\n",
            "12/12 - 0s - loss: 0.4821 - accuracy: 0.8641 - 131ms/epoch - 11ms/step\n",
            "Loss: 0.48210206627845764, Accuracy: 0.864130437374115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### after running the above code, we have created our trained model within the Python session, as well as a folder of checkpoints we can use to restore previous model weights. \n",
        "\n",
        "### we can use keras sequential model's load_weights method to restore the model weights.\n",
        "\n",
        "### to test this, lets define another deep learning model, but restore the weights using the checkpoints rather than training the model."
      ],
      "metadata": {
        "id": "GgSxS15m1FQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer1 = 8\n",
        "hidden_nodes_layer2 = 5\n",
        "\n",
        "nn_new = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn_new.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn_new.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn_new.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Compile the model\n",
        "nn_new.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Restore the model weights\n",
        "nn_new.load_weights(\"checkpoints/weights.100.hdf5\")\n",
        "\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn_new.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aRoIxiH1mJZ",
        "outputId": "839876e5-70fd-44b8-e808-a140108f4c30"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 - 0s - loss: 0.4821 - accuracy: 0.8641 - 230ms/epoch - 19ms/step\n",
            "Loss: 0.48210206627845764, Accuracy: 0.864130437374115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Share the Entire Model"
      ],
      "metadata": {
        "id": "tYsHiAzI2QPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## use keras sequential model's save method to export the entire model ( weights, structure and configuration settings) to an Hierarchical Data Format(HDF5). once saved, anyone can import the exact same trained model to their environment by using Keras load_model method and use it for analysis\n",
        "\n",
        "## to export the trained model: "
      ],
      "metadata": {
        "id": "2vWGDyN42WDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export out model to HDF5 file\n",
        "nn_new.save(\"trained_attrition.h5\")"
      ],
      "metadata": {
        "id": "N37pUF1q20u1"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the model to a new object\n",
        "nn_imported = tf.keras.models.load_model('trained_attrition.h5')"
      ],
      "metadata": {
        "id": "_GJTEXmK3Okb"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the completed model using the test data\n",
        "model_loss, model_accuracy = nn_imported.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpqmeRvJ3kiM",
        "outputId": "cac88244-445f-42d0-bee4-6b273972d0f7"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 - 0s - loss: 0.4821 - accuracy: 0.8641 - 281ms/epoch - 23ms/step\n",
            "Loss: 0.48210206627845764, Accuracy: 0.864130437374115\n"
          ]
        }
      ]
    }
  ]
}